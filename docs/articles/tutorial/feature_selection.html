<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- Google Site Verification --><meta name="google-site-verification" content="BrjL5fpoyHZu1rR8rwnnM2MBO3u3iIFB8NsmSuOsY84">
<title>Feature Selection • mlr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="Feature Selection">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
<link rel="icon" type="image/png" href="https://mlr-org.github.io/mlr/favicon.ico">
<link rel="apple-touch-icon" type="image/png" href="https://mlr-org.github.io/mlr/favicon.ico">
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="../../index.html"></a>
      </div>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/task.html">Tasks</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learner.html">Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/train.html">Train</a>
    </li>
    <li>
      <a href="../../articles/tutorial/predict.html">Predict</a>
    </li>
    <li>
      <a href="../../articles/tutorial/preproc.html">Preprocessing</a>
    </li>
    <li>
      <a href="../../articles/tutorial/performance.html">Performance</a>
    </li>
    <li>
      <a href="../../articles/tutorial/resample.html">Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/tune.html">Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/benchmark_experiments.html">Benchmark Experiments</a>
    </li>
    <li>
      <a href="../../articles/tutorial/parallelization.html">Parallelization</a>
    </li>
    <li>
      <a href="../../articles/tutorial/visualization.html">Visualization</a>
    </li>
    <li>
      <a href="../../articles/tutorial/usecase_regression.html">Use case - Regression</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/configureMlr.html">Configuration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/wrapper.html">Wrapped Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/impute.html">Imputation</a>
    </li>
    <li>
      <a href="../../articles/tutorial/bagging.html">Generic Bagging</a>
    </li>
    <li>
      <a href="../../articles/tutorial/advanced_tune.html">Advanced Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/feature_selection.html">Feature Selection/Filtering</a>
    </li>
    <li>
      <a href="../../articles/tutorial/nested_resampling.html">Nested Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/cost_sensitive_classif.html">Cost-Sensitive Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/over_and_undersampling.html">Imbalanced Classification Problems</a>
    </li>
    <li>
      <a href="../../articles/tutorial/roc_analysis.html">ROC Analysis and Performance Curves</a>
    </li>
    <li>
      <a href="../../articles/tutorial/multilabel.html">Multilabel Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learning_curve.html">Learning Curve Analysis</a>
    </li>
    <li>
      <a href="../../articles/tutorial/partial_dependence.html">Partial Dependence Plots</a>
    </li>
    <li>
      <a href="../../articles/tutorial/classifier_calibration.html">Classifier Calibration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/hyperpar_tuning_effects.html">Hyperparameter Tuning Effects</a>
    </li>
    <li>
      <a href="../../articles/tutorial/out_of_bag_predictions.html">Out-of-Bag Predictions</a>
    </li>
    <li>
      <a href="../../articles/tutorial/handling_of_spatial_data.html">Handling of Spatial Data</a>
    </li>
    <li>
      <a href="../../articles/tutorial/functional_data.html">Functional Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extending
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/create_learner.html">Create Custom Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_measure.html">Create Custom Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_imputation.html">Create Imputation Methods</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_filter.html">Create Custom Filters</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Appendix
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../reference/index.html">Function Reference</a>
    </li>
    <li>
      <a href="../../news/index.html">News</a>
    </li>
    <li>
      <a href="../../articles/tutorial/example_tasks.html">Example Tasks</a>
    </li>
    <li>
      <a href="../../articles/tutorial/integrated_learners.html">Integrated Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/measures.html">Implemented Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/filter_methods.html">Integrated Filter Methods</a>
    </li>
    <li>
      <a href="../../articles/tutorial/mlr_publications.html">mlr Publications</a>
    </li>
    <li>
      <a href="../../articles/tutorial/talks_videos_workshops.html">Talks, Videos and Workshops</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    mlr-org Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="https://github.com/mlr-org/mlrMBO">mlrMBO</a>
    </li>
    <li>
      <a href="https://github.com/mlr-org/mlrCPO">mlrCPO</a>
    </li>
    <li>
      <a href="https://jakob-r.de/mlrHyperopt/index.html">mlrHyperopt</a>
    </li>
    <li>
      <a href="https://openml.github.io/openml-r/vignettes/OpenML.html">OpenML</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mlr-org/mlr">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://mlr-org.slack.com">
    <span class="fa fa-slack"></span>
     
  </a>
</li>
<li>
  <a href="https://stackoverflow.com/questions/tagged/mlr">
    <span class="fa fa-stack-overflow"></span>
     
  </a>
</li>
<li>
  <a href="https://mlr-blog.netlify.com/">
    <span class="fa fa-rss"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right" role="search">
        <div class="form-group">
          <input type="search" class="form-control" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Feature Selection</h1>
            
      
      <!--The 'toc' block was inserted manually by @pat-s. It triggeres the inline ToC in the vignettes.-->
            <div id="toc">
      <h3 class="hasAnchor">
<a href="#toc" class="anchor"></a>Table of Contents</h3>
      <ul>
<li>
<a href="#filter-methods">Filter methods</a><ul>
<li><a href="#calculating-the-feature-importance">Calculating the feature importance</a></li>
      <li><a href="#selecting-a-feature-subset">Selecting a feature subset</a></li>
      <li>
<a href="#fuse-a-learner-with-a-filter-method">Fuse a learner with a filter method</a><ul>
<li><a href="#using-fixed-parameters">Using fixed parameters</a></li>
      <li><a href="#tuning-the-size-of-the-feature-subset">Tuning the size of the feature subset</a></li>
      </ul>
</li>
      </ul>
</li>
      <li>
<a href="#wrapper-methods">Wrapper methods</a><ul>
<li><a href="#select-a-feature-subset">Select a feature subset</a></li>
      <li><a href="#fuse-a-learner-with-feature-selection">Fuse a learner with feature selection</a></li>
      </ul>
</li>
      <li><a href="#feature-importance-from-trained-models">Feature importance from trained models</a></li>
      </ul>
</div>
      
      <small>Source: <a href="https://github.com/mlr-org/mlr/blob/master/vignettes/tutorial/feature_selection.Rmd"><code>vignettes/tutorial/feature_selection.Rmd</code></a></small>

    </div>

    
    
<div class="contents">
<p>Often, data sets include a large number of features. The technique of extracting a subset of relevant features is called feature selection. Feature selection can enhance the interpretability of the model, speed up the learning process and improve the learner performance. There exist different approaches to identify the relevant features. In the literature two different approaches exist: One is called “Filtering” and the other approach is often referred to as “feature subset selection” or “wrapper methods”.</p>
<p>What is the difference?</p>
<ul>
<li>
<strong>Filter</strong>: An external algorithm computes a rank of the variables (e.g. based on the correlation to the response). Then, features are subsetted by a certain criteria, e.g. an absolute number or a percentage of the number of variables. The selected features will then be used to fit a model (with optional hyperparameters selected by tuning). This calculation is usually cheaper than “feature subset selection” in terms of computation time.</li>
<li>
<strong>Feature subset selection</strong>: Here, no ranking of features is done. Features are selected by a (random) subset of the data. Then, a model is fit and the performance is checked. This is done for a lot of feature combinations in a CV setting and the best combination is reported. This method is very computational intense as a lot of models are fitted. Also, strictly all these models would need to be tuned before the performance is estimated which would require an additional nested level in a CV setting. After all this, the selected subset of features is again fitted (with optional hyperparameters selected by tuning).</li>
</ul>
<p><code>mlr</code> supports both <strong><a href="feature_selection.html#filter-methods" target="_blank">filter methods</a></strong> and <strong><a href="feature_selection.html#wrapper-methods" target="_blank">wrapper methods</a></strong>.</p>
<div id="filter-methods" class="section level1">
<h1 class="hasAnchor">
<a href="#filter-methods" class="anchor"></a>Filter methods</h1>
<p>Filter methods assign an importance value to each feature. Based on these values the features can be ranked and a feature subset can be selected. You can see <a href="filter_methods.html#current-methods">here</a> which algorithms are implemented.</p>
<div id="calculating-the-feature-importance" class="section level2">
<h2 class="hasAnchor">
<a href="#calculating-the-feature-importance" class="anchor"></a>Calculating the feature importance</h2>
<p>Different methods for calculating the feature importance are built into <code>mlr</code>’s function <code><a href="../../reference/generateFilterValuesData.html">generateFilterValuesData()</a></code>. Currently, classification, regression and survival analysis tasks are supported. A table showing all available methods can be found in article <a href="filter_methods.html" target="_blank">filter methods</a>.</p>
<p>The most basic approach is to use <code><a href="../../reference/generateFilterValuesData.html">generateFilterValuesData()</a></code> directly on a <code><a href="../../reference/Task.html">Task()</a></code> with a character string specifying the filter method.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">fv =<span class="st"> </span><span class="kw"><a href="../../reference/generateFilterValuesData.html">generateFilterValuesData</a></span>(iris.task, <span class="dt">method =</span> <span class="st">"FSelectorRcpp_information.gain"</span>)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">fv</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="co">## FilterValues:</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="co">## Task: iris-example</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="co">##           name    type FSelectorRcpp_information.gain</span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="co">## 1 Sepal.Length numeric                      0.4521286</span></a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="co">## 2  Sepal.Width numeric                      0.2672750</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="co">## 3 Petal.Length numeric                      0.9402853</span></a>
<a class="sourceLine" id="cb1-9" data-line-number="9"><span class="co">## 4  Petal.Width numeric                      0.9554360</span></a></code></pre></div>
<p><code>fv</code> is a <code><a href="../../reference/generateFilterValuesData.html">FilterValues()</a></code> object and <code>fv$data</code> contains a <code>data.frame</code> that gives the importance values for all features. Optionally, a vector of filter methods can be passed.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">fv2 =<span class="st"> </span><span class="kw"><a href="../../reference/generateFilterValuesData.html">generateFilterValuesData</a></span>(iris.task, </a>
<a class="sourceLine" id="cb2-2" data-line-number="2">  <span class="dt">method =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">"FSelectorRcpp_information.gain"</span>, <span class="st">"FSelector_chi.squared"</span>))</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">fv2<span class="op">$</span>data</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="co">##           name    type FSelectorRcpp_information.gain</span></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="co">## 1 Sepal.Length numeric                      0.4521286</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="co">## 2  Sepal.Width numeric                      0.2672750</span></a>
<a class="sourceLine" id="cb2-7" data-line-number="7"><span class="co">## 3 Petal.Length numeric                      0.9402853</span></a>
<a class="sourceLine" id="cb2-8" data-line-number="8"><span class="co">## 4  Petal.Width numeric                      0.9554360</span></a>
<a class="sourceLine" id="cb2-9" data-line-number="9"><span class="co">##   FSelector_chi.squared</span></a>
<a class="sourceLine" id="cb2-10" data-line-number="10"><span class="co">## 1             0.6288067</span></a>
<a class="sourceLine" id="cb2-11" data-line-number="11"><span class="co">## 2             0.4922162</span></a>
<a class="sourceLine" id="cb2-12" data-line-number="12"><span class="co">## 3             0.9346311</span></a>
<a class="sourceLine" id="cb2-13" data-line-number="13"><span class="co">## 4             0.9432359</span></a></code></pre></div>
<p>A bar plot of importance values for the individual features can be obtained using function <code><a href="../../reference/plotFilterValues.html">plotFilterValues()</a></code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="kw"><a href="../../reference/plotFilterValues.html">plotFilterValues</a></span>(fv2) <span class="op">+</span><span class="st"> </span>ggpubr<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggpubr/topics/theme_pubr">theme_pubr</a></span>()</a></code></pre></div>
<p><img src="feature_selection_files/figure-html/unnamed-chunk-4-1.png" width="960"></p>
<p>By default <code><a href="../../reference/plotFilterValues.html">plotFilterValues()</a></code> will create facetted subplots if multiple filter methods are passed as input to <code><a href="../../reference/generateFilterValuesData.html">generateFilterValuesData()</a></code>.</p>
<p>According to the <code>"information.gain"</code> measure, <code>Petal.Width</code> and <code>Petal.Length</code> contain the most information about the target variable <code>Species</code>.</p>
</div>
<div id="selecting-a-feature-subset" class="section level2">
<h2 class="hasAnchor">
<a href="#selecting-a-feature-subset" class="anchor"></a>Selecting a feature subset</h2>
<p>With <code>mlr</code>s function <code><a href="../../reference/filterFeatures.html">filterFeatures()</a></code> you can create a new <code><a href="../../reference/Task.html">Task()</a></code> by leaving out features of lower importance.</p>
<p>There are several ways to select a feature subset based on feature importance values:</p>
<ul>
<li>Keep a certain <strong>absolute number</strong> (<code>abs</code>) of features with highest importance.</li>
<li>Keep a certain <strong>percentage</strong> (<code>perc</code>) of features with highest importance.</li>
<li>Keep all features whose importance exceeds a certain <em>threshold value</em> (<code>threshold</code>).</li>
</ul>
<p>Function <code><a href="../../reference/filterFeatures.html">filterFeatures()</a></code> supports these three methods as shown in the following example. Moreover, you can either specify the <code>method</code> for calculating the feature importance or you can use previously computed importance values via argument <code>fval</code>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="co"># Keep the 2 most important features</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">filtered.task =<span class="st"> </span><span class="kw"><a href="../../reference/filterFeatures.html">filterFeatures</a></span>(iris.task, <span class="dt">method =</span> <span class="st">"FSelectorRcpp_information.gain"</span>, <span class="dt">abs =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb4-3" data-line-number="3"></a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="co"># Keep the 25% most important features</span></a>
<a class="sourceLine" id="cb4-5" data-line-number="5">filtered.task =<span class="st"> </span><span class="kw"><a href="../../reference/filterFeatures.html">filterFeatures</a></span>(iris.task, <span class="dt">fval =</span> fv, <span class="dt">perc =</span> <span class="fl">0.25</span>)</a>
<a class="sourceLine" id="cb4-6" data-line-number="6"></a>
<a class="sourceLine" id="cb4-7" data-line-number="7"><span class="co"># Keep all features with importance greater than 0.5</span></a>
<a class="sourceLine" id="cb4-8" data-line-number="8">filtered.task =<span class="st"> </span><span class="kw"><a href="../../reference/filterFeatures.html">filterFeatures</a></span>(iris.task, <span class="dt">fval =</span> fv, <span class="dt">threshold =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb4-9" data-line-number="9">filtered.task</a>
<a class="sourceLine" id="cb4-10" data-line-number="10"><span class="co">## Supervised task: iris-example</span></a>
<a class="sourceLine" id="cb4-11" data-line-number="11"><span class="co">## Type: classif</span></a>
<a class="sourceLine" id="cb4-12" data-line-number="12"><span class="co">## Target: Species</span></a>
<a class="sourceLine" id="cb4-13" data-line-number="13"><span class="co">## Observations: 150</span></a>
<a class="sourceLine" id="cb4-14" data-line-number="14"><span class="co">## Features:</span></a>
<a class="sourceLine" id="cb4-15" data-line-number="15"><span class="co">##    numerics     factors     ordered functionals </span></a>
<a class="sourceLine" id="cb4-16" data-line-number="16"><span class="co">##           2           0           0           0 </span></a>
<a class="sourceLine" id="cb4-17" data-line-number="17"><span class="co">## Missings: FALSE</span></a>
<a class="sourceLine" id="cb4-18" data-line-number="18"><span class="co">## Has weights: FALSE</span></a>
<a class="sourceLine" id="cb4-19" data-line-number="19"><span class="co">## Has blocking: FALSE</span></a>
<a class="sourceLine" id="cb4-20" data-line-number="20"><span class="co">## Has coordinates: FALSE</span></a>
<a class="sourceLine" id="cb4-21" data-line-number="21"><span class="co">## Classes: 3</span></a>
<a class="sourceLine" id="cb4-22" data-line-number="22"><span class="co">##     setosa versicolor  virginica </span></a>
<a class="sourceLine" id="cb4-23" data-line-number="23"><span class="co">##         50         50         50 </span></a>
<a class="sourceLine" id="cb4-24" data-line-number="24"><span class="co">## Positive class: NA</span></a></code></pre></div>
</div>
<div id="fuse-a-learner-with-a-filter-method" class="section level2">
<h2 class="hasAnchor">
<a href="#fuse-a-learner-with-a-filter-method" class="anchor"></a>Fuse a learner with a filter method</h2>
<p>Often feature selection based on a filter method is part of the data preprocessing and in a subsequent step a learning method is applied to the filtered data. In a proper experimental setup you might want to automate the selection of the features so that it can be part of the validation method of your choice. A Learner (<code><a href="../../reference/makeLearner.html">makeLearner()</a></code>) can be fused with a filter method by function <code><a href="../../reference/makeFilterWrapper.html">makeFilterWrapper()</a></code>. The resulting Learner (<code><a href="../../reference/makeLearner.html">makeLearner()</a></code>) has the additional class attribute <code>FilterWrapper()</code>. This has the advantage that the filter parameters (<code>fw.method</code>, <code>fw.perc.</code> <code>fw.abs</code>) can now be treated as hyperparameters. They can be tuned in a nested CV setting at the same level as the algorithm hyperparameters. You can think of if as “tuning the dataset”.</p>
<div id="using-fixed-parameters" class="section level3">
<h3 class="hasAnchor">
<a href="#using-fixed-parameters" class="anchor"></a>Using fixed parameters</h3>
<p>In the following example we calculate the 10-fold cross-validated error rate <a href="measures.html" target="_blank">mmce</a> of the k-nearest neighbor classifier (<code>FNN::fnn()</code>) with preceding feature selection on the <code>iris</code> (<code><a href="https://www.rdocumentation.org/packages/datasets/topics/iris">datasets::iris()</a></code>) data set. We use <code>information.gain</code> as importance measure with the aim to subset the dataset to the two features with the highest importance. In each resampling iteration feature selection is carried out on the corresponding training data set before fitting the learner.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeFilterWrapper.html">makeFilterWrapper</a></span>(<span class="dt">learner =</span> <span class="st">"classif.fnn"</span>, </a>
<a class="sourceLine" id="cb5-2" data-line-number="2">  <span class="dt">fw.method =</span> <span class="st">"FSelectorRcpp_information.gain"</span>, <span class="dt">fw.abs =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb5-3" data-line-number="3">rdesc =<span class="st"> </span><span class="kw"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span>(<span class="st">"CV"</span>, <span class="dt">iters =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">r =<span class="st"> </span><span class="kw"><a href="../../reference/resample.html">resample</a></span>(<span class="dt">learner =</span> lrn, <span class="dt">task =</span> iris.task, <span class="dt">resampling =</span> rdesc, <span class="dt">show.info =</span> <span class="ot">FALSE</span>, <span class="dt">models =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">r<span class="op">$</span>aggr</a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="co">## mmce.test.mean </span></a>
<a class="sourceLine" id="cb5-7" data-line-number="7"><span class="co">##           0.04</span></a></code></pre></div>
<p>You may want to know which features have been used. Luckily, we have called <code><a href="../../reference/resample.html">resample()</a></code> with the argument <code>models = TRUE</code>, which means that <code>r$models</code> contains a <code>list</code> of models (<code><a href="../../reference/makeWrappedModel.html">makeWrappedModel()</a></code>) fitted in the individual resampling iterations. In order to access the selected feature subsets we can call <code><a href="../../reference/getFilteredFeatures.html">getFilteredFeatures()</a></code> on each model.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">sfeats =<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/lapply">sapply</a></span>(r<span class="op">$</span>models, getFilteredFeatures)</a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/table">table</a></span>(sfeats)</a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="co">## sfeats</span></a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="co">## Petal.Length  Petal.Width </span></a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="co">##           10           10</span></a></code></pre></div>
<p>The result shows that in the ten folds always <code>Petal.Length</code> and <code>Petal.Width</code> have been chosen (remember we wanted to have the best two, i.e. <span class="math inline">\(10 \times 2\)</span>). The selection of features seems to be very stable for this dataset. The features <code>Sepal.Length</code> and <code>Sepal.Width</code> did not make it into a single fold.</p>
</div>
<div id="tuning-the-size-of-the-feature-subset" class="section level3">
<h3 class="hasAnchor">
<a href="#tuning-the-size-of-the-feature-subset" class="anchor"></a>Tuning the size of the feature subset</h3>
<p>In the above examples the number/percentage of features to select or the threshold value have been arbitrarily chosen. However, it is usually unclear which subset of features will results in the best performance. To answer this question, we can <a href="tune.html" target="_blank">tune</a> the number of features that are taken (after the ranking of the chosen algorithms was applied) as a subset in each fold. Three tunable parameters exist in <code>mlr</code>, documented in <code><a href="../../reference/makeFilterWrapper.html">makeFilterWrapper()</a></code>:</p>
<ul>
<li>The percentage of features selected (<code>fw.perc</code>)</li>
<li>The absolute number of features selected (<code>fw.abs</code>)</li>
<li>The threshold of the filter method (<code>fw.threshold</code>)</li>
</ul>
<p>In the following regression example we consider the <code>BostonHousing</code> (<code><a href="https://www.rdocumentation.org/packages/mlbench/topics/BostonHousing">mlbench::BostonHousing()</a></code>) data set. We use a Support Vector Machine and determine the optimal percentage value for feature selection such that the 3-fold cross-validated mean squared error (<code><a href="../../reference/measures.html">mse()</a></code>) of the learner is minimal. Additionally, we <a href="tune.html" target="_blank">tune</a> the hyperparameters of the algorithm at the same time. As search strategy for tuning a random search with five iterations is used.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeFilterWrapper.html">makeFilterWrapper</a></span>(<span class="dt">learner =</span> <span class="st">"regr.ksvm"</span>, <span class="dt">fw.method =</span> <span class="st">"FSelector_chi.squared"</span>)</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">ps =<span class="st"> </span><span class="kw">makeParamSet</span>(<span class="kw">makeNumericParam</span>(<span class="st">"fw.perc"</span>, <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">                  <span class="kw">makeNumericParam</span>(<span class="st">"C"</span>, <span class="dt">lower =</span> <span class="dv">-10</span>, <span class="dt">upper =</span> <span class="dv">10</span>, </a>
<a class="sourceLine" id="cb7-4" data-line-number="4">                    <span class="dt">trafo =</span> <span class="cf">function</span>(x) <span class="dv">2</span><span class="op">^</span>x),</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">                  <span class="kw">makeNumericParam</span>(<span class="st">"sigma"</span>, <span class="dt">lower =</span> <span class="dv">-10</span>, <span class="dt">upper =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb7-6" data-line-number="6">                    <span class="dt">trafo =</span> <span class="cf">function</span>(x) <span class="dv">2</span><span class="op">^</span>x)</a>
<a class="sourceLine" id="cb7-7" data-line-number="7">                  )</a>
<a class="sourceLine" id="cb7-8" data-line-number="8">rdesc =<span class="st"> </span><span class="kw"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span>(<span class="st">"CV"</span>, <span class="dt">iters =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb7-9" data-line-number="9">res =<span class="st"> </span><span class="kw"><a href="../../reference/tuneParams.html">tuneParams</a></span>(lrn, <span class="dt">task =</span> bh.task, <span class="dt">resampling =</span> rdesc, <span class="dt">par.set =</span> ps,</a>
<a class="sourceLine" id="cb7-10" data-line-number="10">  <span class="dt">control =</span> <span class="kw"><a href="../../reference/makeTuneControlRandom.html">makeTuneControlRandom</a></span>(<span class="dt">maxit =</span> <span class="dv">5</span>))</a>
<a class="sourceLine" id="cb7-11" data-line-number="11"><span class="co">## [Tune] Started tuning learner regr.ksvm.filtered for parameter set:</span></a>
<a class="sourceLine" id="cb7-12" data-line-number="12"><span class="co">##            Type len Def    Constr Req Tunable Trafo</span></a>
<a class="sourceLine" id="cb7-13" data-line-number="13"><span class="co">## fw.perc numeric   -   -    0 to 1   -    TRUE     -</span></a>
<a class="sourceLine" id="cb7-14" data-line-number="14"><span class="co">## C       numeric   -   - -10 to 10   -    TRUE     Y</span></a>
<a class="sourceLine" id="cb7-15" data-line-number="15"><span class="co">## sigma   numeric   -   - -10 to 10   -    TRUE     Y</span></a>
<a class="sourceLine" id="cb7-16" data-line-number="16"><span class="co">## With control class: TuneControlRandom</span></a>
<a class="sourceLine" id="cb7-17" data-line-number="17"><span class="co">## Imputation value: Inf</span></a>
<a class="sourceLine" id="cb7-18" data-line-number="18"><span class="co">## [Tune-x] 1: fw.perc=0.846; C=0.0261; sigma=17.1</span></a>
<a class="sourceLine" id="cb7-19" data-line-number="19"><span class="co">## [Tune-y] 1: mse.test.mean=86.1394358; time: 0.0 min</span></a>
<a class="sourceLine" id="cb7-20" data-line-number="20"><span class="co">## [Tune-x] 2: fw.perc=0.108; C=47.9; sigma=0.0335</span></a>
<a class="sourceLine" id="cb7-21" data-line-number="21"><span class="co">## [Tune-y] 2: mse.test.mean=63.8491956; time: 0.0 min</span></a>
<a class="sourceLine" id="cb7-22" data-line-number="22"><span class="co">## [Tune-x] 3: fw.perc=0.548; C=0.00156; sigma=69.7</span></a>
<a class="sourceLine" id="cb7-23" data-line-number="23"><span class="co">## [Tune-y] 3: mse.test.mean=86.3187611; time: 0.0 min</span></a>
<a class="sourceLine" id="cb7-24" data-line-number="24"><span class="co">## [Tune-x] 4: fw.perc=0.338; C=321; sigma=0.138</span></a>
<a class="sourceLine" id="cb7-25" data-line-number="25"><span class="co">## [Tune-y] 4: mse.test.mean=21.3827291; time: 0.0 min</span></a>
<a class="sourceLine" id="cb7-26" data-line-number="26"><span class="co">## [Tune-x] 5: fw.perc=0.975; C=0.201; sigma=0.855</span></a>
<a class="sourceLine" id="cb7-27" data-line-number="27"><span class="co">## [Tune-y] 5: mse.test.mean=58.7790094; time: 0.0 min</span></a>
<a class="sourceLine" id="cb7-28" data-line-number="28"><span class="co">## [Tune] Result: fw.perc=0.338; C=321; sigma=0.138 : mse.test.mean=21.3827291</span></a>
<a class="sourceLine" id="cb7-29" data-line-number="29">res</a>
<a class="sourceLine" id="cb7-30" data-line-number="30"><span class="co">## Tune result:</span></a>
<a class="sourceLine" id="cb7-31" data-line-number="31"><span class="co">## Op. pars: fw.perc=0.338; C=321; sigma=0.138</span></a>
<a class="sourceLine" id="cb7-32" data-line-number="32"><span class="co">## mse.test.mean=21.3827291</span></a></code></pre></div>
<p>The performance of all percentage values visited during tuning is:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">df =<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/as.data.frame">as.data.frame</a></span>(res<span class="op">$</span>opt.path)</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">df[, <span class="op">-</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">ncol</a></span>(df)]</a>
<a class="sourceLine" id="cb8-3" data-line-number="3"><span class="co">##     fw.perc         C      sigma mse.test.mean dob eol error.message</span></a>
<a class="sourceLine" id="cb8-4" data-line-number="4"><span class="co">## 1 0.8461958 -5.262548  4.0975570      86.13944   1  NA          &lt;NA&gt;</span></a>
<a class="sourceLine" id="cb8-5" data-line-number="5"><span class="co">## 2 0.1076088  5.581377 -4.8978863      63.84920   2  NA          &lt;NA&gt;</span></a>
<a class="sourceLine" id="cb8-6" data-line-number="6"><span class="co">## 3 0.5480433 -9.321970  6.1221895      86.31876   3  NA          &lt;NA&gt;</span></a>
<a class="sourceLine" id="cb8-7" data-line-number="7"><span class="co">## 4 0.3377528  8.325717 -2.8578716      21.38273   4  NA          &lt;NA&gt;</span></a>
<a class="sourceLine" id="cb8-8" data-line-number="8"><span class="co">## 5 0.9753650 -2.312430 -0.2265293      58.77901   5  NA          &lt;NA&gt;</span></a></code></pre></div>
<p>The optimal percentage and the corresponding performance can be accessed as follows:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1">res<span class="op">$</span>x</a>
<a class="sourceLine" id="cb9-2" data-line-number="2"><span class="co">## $fw.perc</span></a>
<a class="sourceLine" id="cb9-3" data-line-number="3"><span class="co">## [1] 0.3377528</span></a>
<a class="sourceLine" id="cb9-4" data-line-number="4"><span class="co">## </span></a>
<a class="sourceLine" id="cb9-5" data-line-number="5"><span class="co">## $C</span></a>
<a class="sourceLine" id="cb9-6" data-line-number="6"><span class="co">## [1] 320.8415</span></a>
<a class="sourceLine" id="cb9-7" data-line-number="7"><span class="co">## </span></a>
<a class="sourceLine" id="cb9-8" data-line-number="8"><span class="co">## $sigma</span></a>
<a class="sourceLine" id="cb9-9" data-line-number="9"><span class="co">## [1] 0.1379415</span></a>
<a class="sourceLine" id="cb9-10" data-line-number="10">res<span class="op">$</span>y</a>
<a class="sourceLine" id="cb9-11" data-line-number="11"><span class="co">## mse.test.mean </span></a>
<a class="sourceLine" id="cb9-12" data-line-number="12"><span class="co">##      21.38273</span></a></code></pre></div>
<p>After tuning we can generate a new wrapped learner with the optimal percentage value for further use (e.g. to predict to new data).</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeFilterWrapper.html">makeFilterWrapper</a></span>(<span class="dt">learner =</span> <span class="st">"regr.lm"</span>, <span class="dt">fw.method =</span> <span class="st">"FSelector_chi.squared"</span>, </a>
<a class="sourceLine" id="cb10-2" data-line-number="2">        <span class="dt">fw.perc =</span> res<span class="op">$</span>x<span class="op">$</span>fw.perc, <span class="dt">C =</span> res<span class="op">$</span>x<span class="op">$</span>C, <span class="dt">sigma =</span> res<span class="op">$</span>x<span class="op">$</span>sigma)</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, bh.task)</a>
<a class="sourceLine" id="cb10-4" data-line-number="4">mod</a>
<a class="sourceLine" id="cb10-5" data-line-number="5"><span class="co">## Model for learner.id=regr.lm.filtered; learner.class=FilterWrapper</span></a>
<a class="sourceLine" id="cb10-6" data-line-number="6"><span class="co">## Trained on: task.id = BostonHousing-example; obs = 506; features = 13</span></a>
<a class="sourceLine" id="cb10-7" data-line-number="7"><span class="co">## Hyperparameters: fw.method=FSelector_ch...,fw.perc=0.338</span></a>
<a class="sourceLine" id="cb10-8" data-line-number="8"></a>
<a class="sourceLine" id="cb10-9" data-line-number="9"><span class="kw"><a href="../../reference/getFilteredFeatures.html">getFilteredFeatures</a></span>(mod)</a>
<a class="sourceLine" id="cb10-10" data-line-number="10"><span class="co">## [1] "crim"  "dis"   "rad"   "lstat"</span></a></code></pre></div>
</div>
</div>
</div>
<div id="wrapper-methods" class="section level1">
<h1 class="hasAnchor">
<a href="#wrapper-methods" class="anchor"></a>Wrapper methods</h1>
<p>Wrapper methods use the performance of a learning algorithm to assess the usefulness of a feature set. In order to select a feature subset a learner is trained repeatedly on different feature subsets and the subset which leads to the best learner performance is chosen.</p>
<p>In order to use the wrapper approach we have to decide:</p>
<ul>
<li>How to assess the performance: This involves choosing a performance measure that serves as feature selection criterion and a resampling strategy.</li>
<li>Which learning method to use.</li>
<li>How to search the space of possible feature subsets.</li>
</ul>
<p>The search strategy is defined by functions following the naming convention <code>makeFeatSelControl&lt;search_strategy</code>. The following search strategies are available:</p>
<ul>
<li>Exhaustive search <code>makeFeatSelControlExhaustive</code> (<code>?FeatSelControl()</code>),</li>
<li>Genetic algorithm <code>makeFeatSelControlGA</code> (<code>?FeatSelControl()</code>),</li>
<li>Random search <code>makeFeatSelControlRandom</code> (<code>?FeatSelControl()</code>),</li>
<li>Deterministic forward or backward search <code>makeFeatSelControlSequential</code> (<code>?FeatSelControl()</code>).</li>
</ul>
<div id="select-a-feature-subset" class="section level2">
<h2 class="hasAnchor">
<a href="#select-a-feature-subset" class="anchor"></a>Select a feature subset</h2>
<p>Feature selection can be conducted with function <code><a href="../../reference/selectFeatures.html">selectFeatures()</a></code>.</p>
<p>In the following example we perform an exhaustive search on the <code>Wisconsin Prognostic Breast Cancer</code> (<code><a href="https://www.rdocumentation.org/packages/TH.data/topics/wpbc">TH.data::wpbc()</a></code>) data set. As learning method we use the <code>Cox proportional hazards model</code> (<code><a href="https://www.rdocumentation.org/packages/survival/topics/coxph">survival::coxph()</a></code>). The performance is assessed by the holdout estimate of the concordance index <a href="measures.html" target="_blank">cindex</a>).</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="co"># Specify the search strategy</span></a>
<a class="sourceLine" id="cb11-2" data-line-number="2">ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/FeatSelControl.html">makeFeatSelControlRandom</a></span>(<span class="dt">maxit =</span> 20L)</a>
<a class="sourceLine" id="cb11-3" data-line-number="3">ctrl</a>
<a class="sourceLine" id="cb11-4" data-line-number="4"><span class="co">## FeatSel control: FeatSelControlRandom</span></a>
<a class="sourceLine" id="cb11-5" data-line-number="5"><span class="co">## Same resampling instance: TRUE</span></a>
<a class="sourceLine" id="cb11-6" data-line-number="6"><span class="co">## Imputation value: &lt;worst&gt;</span></a>
<a class="sourceLine" id="cb11-7" data-line-number="7"><span class="co">## Max. features: &lt;not used&gt;</span></a>
<a class="sourceLine" id="cb11-8" data-line-number="8"><span class="co">## Max. iterations: 20</span></a>
<a class="sourceLine" id="cb11-9" data-line-number="9"><span class="co">## Tune threshold: FALSE</span></a>
<a class="sourceLine" id="cb11-10" data-line-number="10"><span class="co">## Further arguments: prob=0.5</span></a></code></pre></div>
<p><code>ctrl</code> is a<code><a href="../../reference/FeatSelControl.html">FeatSelControl()</a></code> object that contains information about the search strategy and potential parameter values.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="co"># Resample description</span></a>
<a class="sourceLine" id="cb12-2" data-line-number="2">rdesc =<span class="st"> </span><span class="kw"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span>(<span class="st">"Holdout"</span>)</a>
<a class="sourceLine" id="cb12-3" data-line-number="3"></a>
<a class="sourceLine" id="cb12-4" data-line-number="4"><span class="co"># Select features</span></a>
<a class="sourceLine" id="cb12-5" data-line-number="5">sfeats =<span class="st"> </span><span class="kw"><a href="../../reference/selectFeatures.html">selectFeatures</a></span>(<span class="dt">learner =</span> <span class="st">"surv.coxph"</span>, <span class="dt">task =</span> wpbc.task, <span class="dt">resampling =</span> rdesc,</a>
<a class="sourceLine" id="cb12-6" data-line-number="6">  <span class="dt">control =</span> ctrl, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb12-7" data-line-number="7">sfeats</a>
<a class="sourceLine" id="cb12-8" data-line-number="8"><span class="co">## FeatSel result:</span></a>
<a class="sourceLine" id="cb12-9" data-line-number="9"><span class="co">## Features (15): mean_perimeter, mean_smoothness, mean_compactne...</span></a>
<a class="sourceLine" id="cb12-10" data-line-number="10"><span class="co">## cindex.test.mean=0.7014085</span></a></code></pre></div>
<p><code>sfeats</code>is a <code>FeatSelResult</code> (<code><a href="../../reference/selectFeatures.html">selectFeatures()</a></code>) object. The selected features and the corresponding performance can be accessed as follows:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">sfeats<span class="op">$</span>x</a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="co">##  [1] "mean_perimeter"      "mean_smoothness"     "mean_compactness"   </span></a>
<a class="sourceLine" id="cb13-3" data-line-number="3"><span class="co">##  [4] "mean_concavepoints"  "SE_radius"           "SE_area"            </span></a>
<a class="sourceLine" id="cb13-4" data-line-number="4"><span class="co">##  [7] "SE_compactness"      "SE_concavepoints"    "SE_symmetry"        </span></a>
<a class="sourceLine" id="cb13-5" data-line-number="5"><span class="co">## [10] "SE_fractaldim"       "worst_texture"       "worst_smoothness"   </span></a>
<a class="sourceLine" id="cb13-6" data-line-number="6"><span class="co">## [13] "worst_compactness"   "worst_concavepoints" "tsize"</span></a>
<a class="sourceLine" id="cb13-7" data-line-number="7">sfeats<span class="op">$</span>y</a>
<a class="sourceLine" id="cb13-8" data-line-number="8"><span class="co">## cindex.test.mean </span></a>
<a class="sourceLine" id="cb13-9" data-line-number="9"><span class="co">##        0.7014085</span></a></code></pre></div>
<p>In a second example we fit a simple linear regression model to the <code>BostonHousing</code> (<code><a href="https://www.rdocumentation.org/packages/mlbench/topics/BostonHousing">mlbench::BostonHousing()</a></code>) data set and use a sequential search to find a feature set that minimizes the mean squared error <a href="measures.html" target="_blank">mse</a>). <code>method = "sfs"</code> indicates that we want to conduct a sequential forward search where features are added to the model until the performance cannot be improved anymore. See the documentation page <code>makeFeatSelControlSequential</code> (<code>?FeatSelControl()</code>) for other available sequential search methods. The search is stopped if the improvement is smaller than <code>alpha = 0.02</code>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="co"># Specify the search strategy</span></a>
<a class="sourceLine" id="cb14-2" data-line-number="2">ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/FeatSelControl.html">makeFeatSelControlSequential</a></span>(<span class="dt">method =</span> <span class="st">"sfs"</span>, <span class="dt">alpha =</span> <span class="fl">0.02</span>)</a>
<a class="sourceLine" id="cb14-3" data-line-number="3"></a>
<a class="sourceLine" id="cb14-4" data-line-number="4"><span class="co"># Select features</span></a>
<a class="sourceLine" id="cb14-5" data-line-number="5">rdesc =<span class="st"> </span><span class="kw"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span>(<span class="st">"CV"</span>, <span class="dt">iters =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb14-6" data-line-number="6">sfeats =<span class="st"> </span><span class="kw"><a href="../../reference/selectFeatures.html">selectFeatures</a></span>(<span class="dt">learner =</span> <span class="st">"regr.lm"</span>, <span class="dt">task =</span> bh.task, <span class="dt">resampling =</span> rdesc, <span class="dt">control =</span> ctrl,</a>
<a class="sourceLine" id="cb14-7" data-line-number="7">  <span class="dt">show.info =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb14-8" data-line-number="8">sfeats</a>
<a class="sourceLine" id="cb14-9" data-line-number="9"><span class="co">## FeatSel result:</span></a>
<a class="sourceLine" id="cb14-10" data-line-number="10"><span class="co">## Features (11): crim, zn, chas, nox, rm, dis, rad, tax, ptratio...</span></a>
<a class="sourceLine" id="cb14-11" data-line-number="11"><span class="co">## mse.test.mean=23.5662834</span></a></code></pre></div>
<p>Further information about the sequential feature selection process can be obtained by function <code><a href="../../reference/analyzeFeatSelResult.html">analyzeFeatSelResult()</a></code>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="kw"><a href="../../reference/analyzeFeatSelResult.html">analyzeFeatSelResult</a></span>(sfeats)</a>
<a class="sourceLine" id="cb15-2" data-line-number="2"><span class="co">## Features         : 11</span></a>
<a class="sourceLine" id="cb15-3" data-line-number="3"><span class="co">## Performance      : mse.test.mean=23.5662834</span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4"><span class="co">## crim, zn, chas, nox, rm, dis, rad, tax, ptratio, b, lstat</span></a>
<a class="sourceLine" id="cb15-5" data-line-number="5"><span class="co">## </span></a>
<a class="sourceLine" id="cb15-6" data-line-number="6"><span class="co">## Path to optimum:</span></a>
<a class="sourceLine" id="cb15-7" data-line-number="7"><span class="co">## - Features:    0  Init   :                       Perf = 84.98  Diff: NA  *</span></a>
<a class="sourceLine" id="cb15-8" data-line-number="8"><span class="co">## - Features:    1  Add    : lstat                 Perf = 39.018  Diff: 45.962  *</span></a>
<a class="sourceLine" id="cb15-9" data-line-number="9"><span class="co">## - Features:    2  Add    : rm                    Perf = 31.119  Diff: 7.8991  *</span></a>
<a class="sourceLine" id="cb15-10" data-line-number="10"><span class="co">## - Features:    3  Add    : ptratio               Perf = 27.914  Diff: 3.2056  *</span></a>
<a class="sourceLine" id="cb15-11" data-line-number="11"><span class="co">## - Features:    4  Add    : b                     Perf = 27.189  Diff: 0.72476  *</span></a>
<a class="sourceLine" id="cb15-12" data-line-number="12"><span class="co">## - Features:    5  Add    : dis                   Perf = 26.271  Diff: 0.91791  *</span></a>
<a class="sourceLine" id="cb15-13" data-line-number="13"><span class="co">## - Features:    6  Add    : nox                   Perf = 25.138  Diff: 1.1332  *</span></a>
<a class="sourceLine" id="cb15-14" data-line-number="14"><span class="co">## - Features:    7  Add    : chas                  Perf = 24.765  Diff: 0.37276  *</span></a>
<a class="sourceLine" id="cb15-15" data-line-number="15"><span class="co">## - Features:    8  Add    : zn                    Perf = 24.472  Diff: 0.29292  *</span></a>
<a class="sourceLine" id="cb15-16" data-line-number="16"><span class="co">## - Features:    9  Add    : crim                  Perf = 24.334  Diff: 0.13811  *</span></a>
<a class="sourceLine" id="cb15-17" data-line-number="17"><span class="co">## - Features:   10  Add    : rad                   Perf = 24.034  Diff: 0.29951  *</span></a>
<a class="sourceLine" id="cb15-18" data-line-number="18"><span class="co">## - Features:   11  Add    : tax                   Perf = 23.566  Diff: 0.46817  *</span></a>
<a class="sourceLine" id="cb15-19" data-line-number="19"><span class="co">## </span></a>
<a class="sourceLine" id="cb15-20" data-line-number="20"><span class="co">## Stopped, because no improving feature was found.</span></a></code></pre></div>
</div>
<div id="fuse-a-learner-with-feature-selection" class="section level2">
<h2 class="hasAnchor">
<a href="#fuse-a-learner-with-feature-selection" class="anchor"></a>Fuse a learner with feature selection</h2>
<p>A Learner (<code><a href="../../reference/makeLearner.html">makeLearner()</a></code>) can be fused with a feature selection strategy (i.e., a search strategy, a performance measure and a resampling strategy) by function <code><a href="../../reference/makeFeatSelWrapper.html">makeFeatSelWrapper()</a></code>. During training features are selected according to the specified selection scheme. Then, the learner is trained on the selected feature subset.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">rdesc =<span class="st"> </span><span class="kw"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span>(<span class="st">"CV"</span>, <span class="dt">iters =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb16-2" data-line-number="2">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeFeatSelWrapper.html">makeFeatSelWrapper</a></span>(<span class="st">"surv.coxph"</span>, <span class="dt">resampling =</span> rdesc,</a>
<a class="sourceLine" id="cb16-3" data-line-number="3">  <span class="dt">control =</span> <span class="kw"><a href="../../reference/FeatSelControl.html">makeFeatSelControlRandom</a></span>(<span class="dt">maxit =</span> <span class="dv">10</span>), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb16-4" data-line-number="4">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, <span class="dt">task =</span> wpbc.task)</a>
<a class="sourceLine" id="cb16-5" data-line-number="5">mod</a>
<a class="sourceLine" id="cb16-6" data-line-number="6"><span class="co">## Model for learner.id=surv.coxph.featsel; learner.class=FeatSelWrapper</span></a>
<a class="sourceLine" id="cb16-7" data-line-number="7"><span class="co">## Trained on: task.id = wpbc-example; obs = 194; features = 32</span></a>
<a class="sourceLine" id="cb16-8" data-line-number="8"><span class="co">## Hyperparameters:</span></a></code></pre></div>
<p>The result of the feature selection can be extracted by function <code><a href="../../reference/getFeatSelResult.html">getFeatSelResult()</a></code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">sfeats =<span class="st"> </span><span class="kw"><a href="../../reference/getFeatSelResult.html">getFeatSelResult</a></span>(mod)</a>
<a class="sourceLine" id="cb17-2" data-line-number="2">sfeats</a>
<a class="sourceLine" id="cb17-3" data-line-number="3"><span class="co">## FeatSel result:</span></a>
<a class="sourceLine" id="cb17-4" data-line-number="4"><span class="co">## Features (17): mean_radius, mean_texture, mean_smoothness, mea...</span></a>
<a class="sourceLine" id="cb17-5" data-line-number="5"><span class="co">## cindex.test.mean=0.6796954</span></a></code></pre></div>
<p>The selected features are:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1">sfeats<span class="op">$</span>x</a>
<a class="sourceLine" id="cb18-2" data-line-number="2"><span class="co">##  [1] "mean_radius"        "mean_texture"       "mean_smoothness"   </span></a>
<a class="sourceLine" id="cb18-3" data-line-number="3"><span class="co">##  [4] "mean_compactness"   "mean_concavepoints" "mean_symmetry"     </span></a>
<a class="sourceLine" id="cb18-4" data-line-number="4"><span class="co">##  [7] "SE_perimeter"       "SE_area"            "SE_compactness"    </span></a>
<a class="sourceLine" id="cb18-5" data-line-number="5"><span class="co">## [10] "SE_concavity"       "SE_concavepoints"   "SE_symmetry"       </span></a>
<a class="sourceLine" id="cb18-6" data-line-number="6"><span class="co">## [13] "worst_texture"      "worst_smoothness"   "worst_compactness" </span></a>
<a class="sourceLine" id="cb18-7" data-line-number="7"><span class="co">## [16] "worst_concavity"    "pnodes"</span></a></code></pre></div>
<p>The 5-fold cross-validated performance of the learner specified above can be computed as follows:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">out.rdesc =<span class="st"> </span><span class="kw"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span>(<span class="st">"CV"</span>, <span class="dt">iters =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb19-2" data-line-number="2"></a>
<a class="sourceLine" id="cb19-3" data-line-number="3">r =<span class="st"> </span><span class="kw"><a href="../../reference/resample.html">resample</a></span>(<span class="dt">learner =</span> lrn, <span class="dt">task =</span> wpbc.task, <span class="dt">resampling =</span> out.rdesc, <span class="dt">models =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb19-4" data-line-number="4">  <span class="dt">show.info =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb19-5" data-line-number="5">r<span class="op">$</span>aggr</a>
<a class="sourceLine" id="cb19-6" data-line-number="6"><span class="co">## cindex.test.mean </span></a>
<a class="sourceLine" id="cb19-7" data-line-number="7"><span class="co">##        0.6861781</span></a></code></pre></div>
<p>The selected feature sets in the individual resampling iterations can be extracted as follows:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/lapply">lapply</a></span>(r<span class="op">$</span>models, getFeatSelResult)</a>
<a class="sourceLine" id="cb20-2" data-line-number="2"><span class="co">## [[1]]</span></a>
<a class="sourceLine" id="cb20-3" data-line-number="3"><span class="co">## FeatSel result:</span></a>
<a class="sourceLine" id="cb20-4" data-line-number="4"><span class="co">## Features (18): mean_radius, mean_perimeter, mean_compactness, ...</span></a>
<a class="sourceLine" id="cb20-5" data-line-number="5"><span class="co">## cindex.test.mean=0.5382065</span></a>
<a class="sourceLine" id="cb20-6" data-line-number="6"><span class="co">## </span></a>
<a class="sourceLine" id="cb20-7" data-line-number="7"><span class="co">## [[2]]</span></a>
<a class="sourceLine" id="cb20-8" data-line-number="8"><span class="co">## FeatSel result:</span></a>
<a class="sourceLine" id="cb20-9" data-line-number="9"><span class="co">## Features (18): mean_radius, mean_perimeter, mean_area, mean_sm...</span></a>
<a class="sourceLine" id="cb20-10" data-line-number="10"><span class="co">## cindex.test.mean=0.6349051</span></a>
<a class="sourceLine" id="cb20-11" data-line-number="11"><span class="co">## </span></a>
<a class="sourceLine" id="cb20-12" data-line-number="12"><span class="co">## [[3]]</span></a>
<a class="sourceLine" id="cb20-13" data-line-number="13"><span class="co">## FeatSel result:</span></a>
<a class="sourceLine" id="cb20-14" data-line-number="14"><span class="co">## Features (20): mean_texture, mean_smoothness, mean_concavity, ...</span></a>
<a class="sourceLine" id="cb20-15" data-line-number="15"><span class="co">## cindex.test.mean=0.6812985</span></a>
<a class="sourceLine" id="cb20-16" data-line-number="16"><span class="co">## </span></a>
<a class="sourceLine" id="cb20-17" data-line-number="17"><span class="co">## [[4]]</span></a>
<a class="sourceLine" id="cb20-18" data-line-number="18"><span class="co">## FeatSel result:</span></a>
<a class="sourceLine" id="cb20-19" data-line-number="19"><span class="co">## Features (11): mean_perimeter, mean_concavity, mean_concavepoi...</span></a>
<a class="sourceLine" id="cb20-20" data-line-number="20"><span class="co">## cindex.test.mean=0.6924829</span></a>
<a class="sourceLine" id="cb20-21" data-line-number="21"><span class="co">## </span></a>
<a class="sourceLine" id="cb20-22" data-line-number="22"><span class="co">## [[5]]</span></a>
<a class="sourceLine" id="cb20-23" data-line-number="23"><span class="co">## FeatSel result:</span></a>
<a class="sourceLine" id="cb20-24" data-line-number="24"><span class="co">## Features (14): mean_area, mean_smoothness, mean_fractaldim, SE...</span></a>
<a class="sourceLine" id="cb20-25" data-line-number="25"><span class="co">## cindex.test.mean=0.6701811</span></a></code></pre></div>
</div>
</div>
<div id="feature-importance-from-trained-models" class="section level1">
<h1 class="hasAnchor">
<a href="#feature-importance-from-trained-models" class="anchor"></a>Feature importance from trained models</h1>
<p>Some algorithms internally compute a feature importance during training. By using <code><a href="../../reference/getFeatureImportance.html">getFeatureImportance()</a></code> it is possible to extract this part from the trained model.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1">task =<span class="st"> </span><span class="kw"><a href="../../reference/Task.html">makeClassifTask</a></span>(<span class="dt">data =</span> iris, <span class="dt">target =</span> <span class="st">"Species"</span>)</a>
<a class="sourceLine" id="cb21-2" data-line-number="2">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.ranger"</span>, <span class="dt">importance =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">"permutation"</span>))</a>
<a class="sourceLine" id="cb21-3" data-line-number="3">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, task)</a>
<a class="sourceLine" id="cb21-4" data-line-number="4"></a>
<a class="sourceLine" id="cb21-5" data-line-number="5"><span class="kw"><a href="../../reference/getFeatureImportance.html">getFeatureImportance</a></span>(mod)</a>
<a class="sourceLine" id="cb21-6" data-line-number="6"><span class="co">## FeatureImportance:</span></a>
<a class="sourceLine" id="cb21-7" data-line-number="7"><span class="co">## Task: iris</span></a>
<a class="sourceLine" id="cb21-8" data-line-number="8"><span class="co">## </span></a>
<a class="sourceLine" id="cb21-9" data-line-number="9"><span class="co">## Learner: classif.ranger</span></a>
<a class="sourceLine" id="cb21-10" data-line-number="10"><span class="co">## Measure: NA</span></a>
<a class="sourceLine" id="cb21-11" data-line-number="11"><span class="co">## Contrast: NA</span></a>
<a class="sourceLine" id="cb21-12" data-line-number="12"><span class="co">## Aggregation: function (x)  x</span></a>
<a class="sourceLine" id="cb21-13" data-line-number="13"><span class="co">## Replace: NA</span></a>
<a class="sourceLine" id="cb21-14" data-line-number="14"><span class="co">## Number of Monte-Carlo iterations: NA</span></a>
<a class="sourceLine" id="cb21-15" data-line-number="15"><span class="co">## Local: FALSE</span></a>
<a class="sourceLine" id="cb21-16" data-line-number="16"><span class="co">##   Sepal.Length Sepal.Width Petal.Length Petal.Width</span></a>
<a class="sourceLine" id="cb21-17" data-line-number="17"><span class="co">## 1   0.03898548 0.007192708    0.3138316   0.2955986</span></a></code></pre></div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#filter-methods">Filter methods</a><ul class="nav nav-pills nav-stacked">
<li><a href="#calculating-the-feature-importance">Calculating the feature importance</a></li>
      <li><a href="#selecting-a-feature-subset">Selecting a feature subset</a></li>
      <li>
<a href="#fuse-a-learner-with-a-filter-method">Fuse a learner with a filter method</a><ul class="nav nav-pills nav-stacked">
<li><a href="#using-fixed-parameters">Using fixed parameters</a></li>
      <li><a href="#tuning-the-size-of-the-feature-subset">Tuning the size of the feature subset</a></li>
      </ul>
</li>
      </ul>
</li>
      <li>
<a href="#wrapper-methods">Wrapper methods</a><ul class="nav nav-pills nav-stacked">
<li><a href="#select-a-feature-subset">Select a feature subset</a></li>
      <li><a href="#fuse-a-learner-with-feature-selection">Fuse a learner with feature selection</a></li>
      </ul>
</li>
      <li><a href="#feature-importance-from-trained-models">Feature importance from trained models</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><!--<div class="copyright">
  <p>Developed by Bernd Bischl, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Zachary Jones, Giuseppe Casalicchio, Mason Gallo, Patrick Schratz.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>
--></footer>
</div>

   
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script><script type="text/javascript"> docsearch({
 apiKey: 'e300ecafdf04fe1199e3339c825ce7d0',
 indexName: 'mlr',
 inputSelector: 'input#search-input.form-control',
 debug: false // Set debug to true if you want to inspect the dropdown
});
</script>
</body>
</html>
