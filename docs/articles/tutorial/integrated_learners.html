<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- Google Site Verification --><meta name="google-site-verification" content="BrjL5fpoyHZu1rR8rwnnM2MBO3u3iIFB8NsmSuOsY84">
<title>Integrated Learners â€¢ mlr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="Integrated Learners">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
<link rel="icon" type="image/png" href="https://mlr-org.github.io/mlr/favicon.ico">
<link rel="apple-touch-icon" type="image/png" href="https://mlr-org.github.io/mlr/favicon.ico">
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="../../index.html"></a>
      </div>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/task.html">Tasks</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learner.html">Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/train.html">Train</a>
    </li>
    <li>
      <a href="../../articles/tutorial/predict.html">Predict</a>
    </li>
    <li>
      <a href="../../articles/tutorial/preproc.html">Preprocessing</a>
    </li>
    <li>
      <a href="../../articles/tutorial/performance.html">Performance</a>
    </li>
    <li>
      <a href="../../articles/tutorial/resample.html">Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/tune.html">Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/benchmark_experiments.html">Benchmark Experiments</a>
    </li>
    <li>
      <a href="../../articles/tutorial/parallelization.html">Parallelization</a>
    </li>
    <li>
      <a href="../../articles/tutorial/visualization.html">Visualization</a>
    </li>
    <li>
      <a href="../../articles/tutorial/usecase_regression.html">Use case - Regression</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/configureMlr.html">Configuration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/wrapper.html">Wrapped Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/impute.html">Imputation</a>
    </li>
    <li>
      <a href="../../articles/tutorial/bagging.html">Generic Bagging</a>
    </li>
    <li>
      <a href="../../articles/tutorial/advanced_tune.html">Advanced Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/feature_selection.html">Feature Selection/Filtering</a>
    </li>
    <li>
      <a href="../../articles/tutorial/nested_resampling.html">Nested Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/cost_sensitive_classif.html">Cost-Sensitive Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/over_and_undersampling.html">Imbalanced Classification Problems</a>
    </li>
    <li>
      <a href="../../articles/tutorial/roc_analysis.html">ROC Analysis and Performance Curves</a>
    </li>
    <li>
      <a href="../../articles/tutorial/multilabel.html">Multilabel Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learning_curve.html">Learning Curve Analysis</a>
    </li>
    <li>
      <a href="../../articles/tutorial/partial_dependence.html">Partial Dependence Plots</a>
    </li>
    <li>
      <a href="../../articles/tutorial/classifier_calibration.html">Classifier Calibration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/hyperpar_tuning_effects.html">Hyperparameter Tuning Effects</a>
    </li>
    <li>
      <a href="../../articles/tutorial/out_of_bag_predictions.html">Out-of-Bag Predictions</a>
    </li>
    <li>
      <a href="../../articles/tutorial/handling_of_spatial_data.html">Handling of Spatial Data</a>
    </li>
    <li>
      <a href="../../articles/tutorial/functional_data.html">Functional Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extending
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/create_learner.html">Create Custom Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_measure.html">Create Custom Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_imputation.html">Create Imputation Methods</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_filter.html">Create Custom Filters</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Appendix
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../reference/index.html">Function Reference</a>
    </li>
    <li>
      <a href="../../news/index.html">News</a>
    </li>
    <li>
      <a href="../../articles/tutorial/example_tasks.html">Example Tasks</a>
    </li>
    <li>
      <a href="../../articles/tutorial/integrated_learners.html">Integrated Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/measures.html">Implemented Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/filter_methods.html">Integrated Filter Methods</a>
    </li>
    <li>
      <a href="../../articles/tutorial/mlr_publications.html">mlr Publications</a>
    </li>
    <li>
      <a href="../../articles/tutorial/talks_videos_workshops.html">Talks, Videos and Workshops</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    mlr-org Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="https://github.com/mlr-org/mlrMBO">mlrMBO</a>
    </li>
    <li>
      <a href="https://github.com/mlr-org/mlrCPO">mlrCPO</a>
    </li>
    <li>
      <a href="https://jakob-r.de/mlrHyperopt/index.html">mlrHyperopt</a>
    </li>
    <li>
      <a href="https://openml.github.io/openml-r/vignettes/OpenML.html">OpenML</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mlr-org/mlr">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://mlr-org.slack.com">
    <span class="fa fa-slack"></span>
     
  </a>
</li>
<li>
  <a href="https://stackoverflow.com/questions/tagged/mlr">
    <span class="fa fa-stack-overflow"></span>
     
  </a>
</li>
<li>
  <a href="https://mlr-blog.netlify.com/">
    <span class="fa fa-rss"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right" role="search">
        <div class="form-group">
          <input type="search" class="form-control" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Integrated Learners</h1>
            
      
      <!--The 'toc' block was inserted manually by @pat-s. It triggeres the inline ToC in the vignettes.-->
            <div id="toc">
      <h3 class="hasAnchor">
<a href="#toc" class="anchor"></a>Table of Contents</h3>
      <ul>
<li><a href="#classification-82">Classification (82)</a></li>
      <li><a href="#regression-59">Regression (59)</a></li>
      <li><a href="#survival-analysis-12">Survival analysis (12)</a></li>
      <li><a href="#cluster-analysis-10">Cluster analysis (10)</a></li>
      <li><a href="#cost-sensitive-classification">Cost-sensitive classification</a></li>
      <li><a href="#multilabel-classification-3">Multilabel classification (3)</a></li>
      </ul>
</div>
      
      <small>Source: <a href="https://github.com/mlr-org/mlr/blob/master/vignettes/tutorial/integrated_learners.Rmd"><code>vignettes/tutorial/integrated_learners.Rmd</code></a></small>

    </div>

    
    
<div class="contents">
<p>This page lists the learning methods already integrated in <code>mlr</code>.</p>
<p>Columns <strong>Num.</strong>, <strong>Fac.</strong>, <strong>Ord.</strong>, <strong>NAs</strong>, and <strong>Weights</strong> indicate if a method can cope with numerical, factor, and ordered factor predictors, if it can deal with missing values in a meaningful way (other than simply removing observations with missing values) and if observation weights are supported.</p>
<p>Column <strong>Props</strong> shows further properties of the learning methods specific to the type of learning task. See also <code><a href="../../reference/RLearner.html">RLearner()</a></code> for details.</p>
<div id="classification-82" class="section level1">
<h1 class="hasAnchor">
<a href="#classification-82" class="anchor"></a>Classification (82)</h1>
<p>For classification the following additional learner properties are relevant and shown in column <strong>Props</strong>:</p>
<ul>
<li>
<em>prob</em>: The method can predict probabilities,</li>
<li>
<em>oneclass</em>, <em>twoclass</em>, <em>multiclass</em>: One-class, two-class (binary) or multi-class classification problems be handled,</li>
<li>
<em>class.weights</em>: Class weights can be handled.</li>
</ul>
<table class="table">
<colgroup>
<col width="11%">
<col width="17%">
<col width="0%">
<col width="0%">
<col width="0%">
<col width="0%">
<col width="0%">
<col width="7%">
<col width="60%">
</colgroup>
<thead><tr class="header">
<th align="left">Class / Short Name / Name</th>
<th align="left">Packages</th>
<th align="center">Num.</th>
<th align="center">Fac.</th>
<th align="center">Ord.</th>
<th align="center">NAs</th>
<th align="center">Weights</th>
<th align="left">Props</th>
<th align="left">Note</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">
<strong>classif.ada</strong> <br><em>ada</em> <br><br>ada Boosting</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/ada/">ada</a><br><a href="http://www.rdocumentation.org/packages/rpart/">rpart</a>
</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass</td>
<td align="left">
<code>xval</code> has been set to <code>0</code> by default for speed.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.adaboostm1</strong> <br><em>adaboostm1</em> <br><br>ada Boosting M1</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">NAs are directly passed to WEKA with <code>na.action = na.pass</code>.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.bartMachine</strong> <br><em>bartmachine</em> <br><br>Bayesian Additive Regression Trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/bartMachine/">bartMachine</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">prob<br>twoclass</td>
<td align="left">
<code>use_missing_data</code> has been set to <code>TRUE</code> by default to allow missing data support.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.binomial</strong> <br><em>binomial</em> <br><br>Binomial Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/stats/">stats</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass</td>
<td align="left">Delegates to <code>glm</code> with freely choosable binomial link function via learner parameter <code>link</code>. We set â€˜modelâ€™ to FALSE by default to save memory.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.boosting</strong> <br><em>adabag</em> <br><br>Adabag Boosting</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/adabag/">adabag</a><br><a href="http://www.rdocumentation.org/packages/rpart/">rpart</a>
</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp</td>
<td align="left">
<code>xval</code> has been set to <code>0</code> by default for speed.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.bst</strong> <br><em>bst</em> <br><br>Gradient Boosting</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/bst/">bst</a><br><a href="http://www.rdocumentation.org/packages/rpart/">rpart</a>
</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass</td>
<td align="left">Renamed parameter <code>learner</code> to <code>Learner</code> due to nameclash with <code>setHyperPars</code>. Default changes: <code>Learner = "ls"</code>, <code>xval = 0</code>, and <code>maxdepth = 1</code>.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.C50</strong> <br><em>C50</em> <br><br>C50</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/C50/">C50</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.cforest</strong> <br><em>cforest</em> <br><br>Random forest based on conditional inference trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/party/">party</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp</td>
<td align="left">See <code>?ctree_control</code> for possible breakage for nominal features with missingness.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.clusterSVM</strong> <br><em>clusterSVM</em> <br><br>Clustered Support Vector Machines</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/SwarmSVM/">SwarmSVM</a><br><a href="http://www.rdocumentation.org/packages/LiblineaR/">LiblineaR</a>
</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass</td>
<td align="left">
<code>centers</code> set to <code>2</code> by default.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.ctree</strong> <br><em>ctree</em> <br><br>Conditional Inference Trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/party/">party</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">See <code>?ctree_control</code> for possible breakage for nominal features with missingness.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.cvglmnet</strong> <br><em>cvglmnet</em> <br><br>GLM with Lasso or Elasticnet Regularization (Cross Validated Lambda)</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/glmnet/">glmnet</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">The family parameter is set to <code>binomial</code> for two-class problems and to <code>multinomial</code> otherwise. Factors automatically get converted to dummy columns, ordered factors to integer. glmnet uses a global control object for its parameters. mlr resets all control parameters to their defaults before setting the specified parameters and after training. If you are setting glmnet.control parameters through glmnet.control, you need to save and re-set them after running the glmnet learner.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.dbnDNN</strong> <br><em>dbn.dnn</em> <br><br>Deep neural network with weights initialized by DBN</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/deepnet/">deepnet</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">
<code>output</code> set to <code>"softmax"</code> by default.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.dcSVM</strong> <br><em>dcSVM</em> <br><br>Divided-Conquer Support Vector Machines</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/SwarmSVM/">SwarmSVM</a><br><a href="http://www.rdocumentation.org/packages/e1071/">e1071</a>
</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.earth</strong> <br><em>fda</em> <br><br>Flexible Discriminant Analysis</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/earth/">earth</a><br><a href="http://www.rdocumentation.org/packages/stats/">stats</a>
</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">This learner performs flexible discriminant analysis using the earth algorithm. na.action is set to na.fail and only this is supported.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.evtree</strong> <br><em>evtree</em> <br><br>Evolutionary learning of globally optimal trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/evtree/">evtree</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">
<code>pmutatemajor</code>, <code>pmutateminor</code>, <code>pcrossover</code>, <code>psplit</code>, and <code>pprune</code>, are scaled internally to sum to 100.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.extraTrees</strong> <br><em>extraTrees</em> <br><br>Extremely Randomized Trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/extraTrees/">extraTrees</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.fdausc.glm</strong> <br><em>fdausc.glm</em> <br><br>Generalized Linear Models classification on FDA</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/fda.usc/">fda.usc</a></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>functionals</td>
<td align="left">model$C[[1]] is set to quote(classif.glm)</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.fdausc.kernel</strong> <br><em>fdausc.kernel</em> <br><br>Kernel classification on FDA</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/fda.usc/">fda.usc</a></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>single.functional</td>
<td align="left">Argument draw=FALSE is used as default.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.fdausc.knn</strong> <br><em>fdausc.knn</em> <br><br>fdausc.knn</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/fda.usc/">fda.usc</a></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass<br>single.functional</td>
<td align="left">Argument draw=FALSE is used as default.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.fdausc.np</strong> <br><em>fdausc.np</em> <br><br>Nonparametric classification on FDA</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/fda.usc/">fda.usc</a></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>single.functional</td>
<td align="left">Argument draw=FALSE is used as default. Additionally, mod$C[[1]] is set to quote(classif.np)</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.featureless</strong> <br><em>featureless</em> <br><br>Featureless classifier</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/">mlr</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>functionals</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.fnn</strong> <br><em>fnn</em> <br><br>Fast k-Nearest Neighbour</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/FNN/">FNN</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.gamboost</strong> <br><em>gamboost</em> <br><br>Gradient boosting with smooth components</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/mboost/">mboost</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass</td>
<td align="left">
<code>family</code> has been set to <code><a href="https://www.rdocumentation.org/packages/stats/topics/Binomial">Binomial()</a></code> by default. For â€˜familyâ€™ â€˜AUCâ€™ and â€˜AdaExpâ€™ probabilities cannot be predicted.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.gaterSVM</strong> <br><em>gaterSVM</em> <br><br>Mixture of SVMs with Neural Network Gater Function</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/SwarmSVM/">SwarmSVM</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass</td>
<td align="left">
<code>m</code> set to <code>3</code> and <code>max.iter</code> set to <code>1</code> by default.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.gausspr</strong> <br><em>gausspr</em> <br><br>Gaussian Processes</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/kernlab/">kernlab</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">Kernel parameters have to be passed directly and not by using the <code>kpar</code> list in <code>gausspr</code>. Note that <code>fit</code> has been set to <code>FALSE</code> by default for speed.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.gbm</strong> <br><em>gbm</em> <br><br>Gradient Boosting Machine</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/gbm/">gbm</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp</td>
<td align="left">
<code>keep.data</code> is set to FALSE to reduce memory requirements. Note on param â€˜distributionâ€™: gbm will select â€˜bernoulliâ€™ by default for 2 classes, and â€˜multinomialâ€™ for multiclass problems. The latter is the only setting that works for &gt; 2 classes.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.geoDA</strong> <br><em>geoda</em> <br><br>Geometric Predictive Discriminant Analysis</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/DiscriMiner/">DiscriMiner</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.glmboost</strong> <br><em>glmboost</em> <br><br>Boosting for GLMs</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/mboost/">mboost</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass</td>
<td align="left">
<code>family</code> has been set to <code>Binomial</code> by default. For â€˜familyâ€™ â€˜AUCâ€™ and â€˜AdaExpâ€™ probabilities cannot be predcited.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.glmnet</strong> <br><em>glmnet</em> <br><br>GLM with Lasso or Elasticnet Regularization</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/glmnet/">glmnet</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">The family parameter is set to <code>binomial</code> for two-class problems and to <code>multinomial</code> otherwise. Factors automatically get converted to dummy columns, ordered factors to integer. Parameter <code>s</code> (value of the regularization parameter used for predictions) is set to <code>0.1</code> by default, but needs to be tuned by the user. glmnet uses a global control object for its parameters. mlr resets all control parameters to their defaults before setting the specified parameters and after training. If you are setting glmnet.control parameters through glmnet.control, you need to save and re-set them after running the glmnet learner.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.h2o.deeplearning</strong> <br><em>h2o.dl</em> <br><br>h2o.deeplearning</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/h2o/">h2o</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp</td>
<td align="left">The default value of <code>missing_values_handling</code> is <code>"MeanImputation"</code>, so missing values are automatically mean-imputed.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.h2o.gbm</strong> <br><em>h2o.gbm</em> <br><br>h2o.gbm</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/h2o/">h2o</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp</td>
<td align="left">â€˜distributionâ€™ is set automatically to â€˜gaussianâ€™.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.h2o.glm</strong> <br><em>h2o.glm</em> <br><br>h2o.glm</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/h2o/">h2o</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>featimp</td>
<td align="left">
<code>family</code> is always set to <code>"binomial"</code> to get a binary classifier. The default value of <code>missing_values_handling</code> is <code>"MeanImputation"</code>, so missing values are automatically mean-imputed.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.h2o.randomForest</strong> <br><em>h2o.rf</em> <br><br>h2o.randomForest</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/h2o/">h2o</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.IBk</strong> <br><em>ibk</em> <br><br>k-Nearest Neighbours</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.J48</strong> <br><em>j48</em> <br><br>J48 Decision Trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">NAs are directly passed to WEKA with <code>na.action = na.pass</code>.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.JRip</strong> <br><em>jrip</em> <br><br>Propositional Rule Learner</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">NAs are directly passed to WEKA with <code>na.action = na.pass</code>.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.kknn</strong> <br><em>kknn</em> <br><br>k-Nearest Neighbor</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/kknn/">kknn</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.knn</strong> <br><em>knn</em> <br><br>k-Nearest Neighbor</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/class/">class</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.ksvm</strong> <br><em>ksvm</em> <br><br>Support Vector Machines</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/kernlab/">kernlab</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>class.weights</td>
<td align="left">Kernel parameters have to be passed directly and not by using the <code>kpar</code> list in <code>ksvm</code>. Note that <code>fit</code> has been set to <code>FALSE</code> by default for speed.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.lda</strong> <br><em>lda</em> <br><br>Linear Discriminant Analysis</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/MASS/">MASS</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">Learner parameter <code>predict.method</code> maps to <code>method</code> in <code>predict.lda</code>.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.LiblineaRL1L2SVC</strong> <br><em>liblinl1l2svc</em> <br><br>L1-Regularized L2-Loss Support Vector Classification</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/LiblineaR/">LiblineaR</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass<br>class.weights</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.LiblineaRL1LogReg</strong> <br><em>liblinl1logreg</em> <br><br>L1-Regularized Logistic Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/LiblineaR/">LiblineaR</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>class.weights</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.LiblineaRL2L1SVC</strong> <br><em>liblinl2l1svc</em> <br><br>L2-Regularized L1-Loss Support Vector Classification</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/LiblineaR/">LiblineaR</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass<br>class.weights</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.LiblineaRL2LogReg</strong> <br><em>liblinl2logreg</em> <br><br>L2-Regularized Logistic Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/LiblineaR/">LiblineaR</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>class.weights</td>
<td align="left">
<code>type = 0</code> (the default) is primal and <code>type = 7</code> is dual problem.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.LiblineaRL2SVC</strong> <br><em>liblinl2svc</em> <br><br>L2-Regularized L2-Loss Support Vector Classification</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/LiblineaR/">LiblineaR</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass<br>class.weights</td>
<td align="left">
<code>type = 2</code> (the default) is primal and <code>type = 1</code> is dual problem.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.LiblineaRMultiClassSVC</strong> <br><em>liblinmulticlasssvc</em> <br><br>Support Vector Classification by Crammer and Singer</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/LiblineaR/">LiblineaR</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass<br>class.weights</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.linDA</strong> <br><em>linda</em> <br><br>Linear Discriminant Analysis</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/DiscriMiner/">DiscriMiner</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass</td>
<td align="left">Set <code>validation = NULL</code> by default to disable internal test set validation.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.logreg</strong> <br><em>logreg</em> <br><br>Logistic Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/stats/">stats</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass</td>
<td align="left">Delegates to <code>glm</code> with <code>family = binomial(link = 'logit')</code>. We set â€˜modelâ€™ to FALSE by default to save memory.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.lssvm</strong> <br><em>lssvm</em> <br><br>Least Squares Support Vector Machine</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/kernlab/">kernlab</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass</td>
<td align="left">
<code>fitted</code> has been set to <code>FALSE</code> by default for speed.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.lvq1</strong> <br><em>lvq1</em> <br><br>Learning Vector Quantization</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/class/">class</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.mda</strong> <br><em>mda</em> <br><br>Mixture Discriminant Analysis</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/mda/">mda</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">
<code>keep.fitted</code> has been set to <code>FALSE</code> by default for speed and we use <code>start.method = "lvq"</code> for more robust behavior / less technical crashes.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.mlp</strong> <br><em>mlp</em> <br><br>Multi-Layer Perceptron</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RSNNS/">RSNNS</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.multinom</strong> <br><em>multinom</em> <br><br>Multinomial Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/nnet/">nnet</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.naiveBayes</strong> <br><em>nbayes</em> <br><br>Naive Bayes</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/e1071/">e1071</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.neuralnet</strong> <br><em>neuralnet</em> <br><br>Neural Network from neuralnet</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/neuralnet/">neuralnet</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass</td>
<td align="left">
<code>err.fct</code> has been set to <code>ce</code> and <code>linear.output</code> to FALSE to do classification.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.nnet</strong> <br><em>nnet</em> <br><br>Neural Network</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/nnet/">nnet</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">
<code>linout=TRUE</code> is hardcoded for regression. <code>size</code> has been set to <code>3</code> by default.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.nnTrain</strong> <br><em>nn.train</em> <br><br>Training Neural Network by Backpropagation</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/deepnet/">deepnet</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">
<code>output</code> set to <code>softmax</code> by default. <code>max.number.of.layers</code> can be set to control and tune the maximal number of layers specified via <code>hidden</code>.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.nodeHarvest</strong> <br><em>nodeHarvest</em> <br><br>Node Harvest</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/nodeHarvest/">nodeHarvest</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.OneR</strong> <br><em>oner</em> <br><br>1-R Classifier</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">NAs are directly passed to WEKA with <code>na.action = na.pass</code>.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.pamr</strong> <br><em>pamr</em> <br><br>Nearest shrunken centroid</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/pamr/">pamr</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass</td>
<td align="left">Threshold for prediction (<code>threshold.predict</code>) has been set to <code>1</code> by default.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.PART</strong> <br><em>part</em> <br><br>PART Decision Lists</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">NAs are directly passed to WEKA with <code>na.action = na.pass</code>.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.penalized</strong> <br><em>penalized</em> <br><br>Penalized Logistic Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/penalized/">penalized</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass</td>
<td align="left">trace=FALSE was set by default to disable logging output.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.plr</strong> <br><em>plr</em> <br><br>Logistic Regression with a L2 Penalty</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/stepPlr/">stepPlr</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass</td>
<td align="left">AIC and BIC penalty types can be selected via the new parameter <code>cp.type</code>.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.plsdaCaret</strong> <br><em>plsdacaret</em> <br><br>Partial Least Squares (PLS) Discriminant Analysis</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/caret/">caret</a><br><a href="http://www.rdocumentation.org/packages/pls/">pls</a>
</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.probit</strong> <br><em>probit</em> <br><br>Probit Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/stats/">stats</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass</td>
<td align="left">Delegates to <code>glm</code> with <code>family = binomial(link = 'probit')</code>. We set â€˜modelâ€™ to FALSE by default to save memory.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.qda</strong> <br><em>qda</em> <br><br>Quadratic Discriminant Analysis</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/MASS/">MASS</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">Learner parameter <code>predict.method</code> maps to <code>method</code> in <code>predict.qda</code>.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.quaDA</strong> <br><em>quada</em> <br><br>Quadratic Discriminant Analysis</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/DiscriMiner/">DiscriMiner</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.randomForest</strong> <br><em>rf</em> <br><br>Random Forest</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/randomForest/">randomForest</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>class.weights<br>featimp<br>oobpreds</td>
<td align="left">Note that the rf can freeze the R process if trained on a task with 1 feature which is constant. This can happen in feature forward selection, also due to resampling, and you need to remove such features with removeConstantFeatures.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.randomForestSRC</strong> <br><em>rfsrc</em> <br><br>Random Forest</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/randomForestSRC/">randomForestSRC</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp<br>oobpreds</td>
<td align="left">
<code>na.action</code> has been set to <code>"na.impute"</code> by default to allow missing data support.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.ranger</strong> <br><em>ranger</em> <br><br>Random Forests</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/ranger/">ranger</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp<br>oobpreds</td>
<td align="left">By default, internal parallelization is switched off (<code>num.threads = 1</code>), <code>verbose</code> output is disabled, <code>respect.unordered.factors</code> is set to <code>order</code> for all splitrules. If predict.type=â€˜probâ€™ we set â€˜probability=TRUEâ€™ in ranger.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.rda</strong> <br><em>rda</em> <br><br>Regularized Discriminant Analysis</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/klaR/">klaR</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">
<code>estimate.error</code> has been set to <code>FALSE</code> by default for speed.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.rFerns</strong> <br><em>rFerns</em> <br><br>Random ferns</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/rFerns/">rFerns</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass<br>oobpreds</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.rknn</strong> <br><em>rknn</em> <br><br>Random k-Nearest-Neighbors</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/rknn/">rknn</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass</td>
<td align="left">k restricted to &lt; 99 as the code allocates arrays of static size</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.rotationForest</strong> <br><em>rotationForest</em> <br><br>Rotation Forest</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/rotationForest/">rotationForest</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.rpart</strong> <br><em>rpart</em> <br><br>Decision Tree</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/rpart/">rpart</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp</td>
<td align="left">
<code>xval</code> has been set to <code>0</code> by default for speed.</td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.RRF</strong> <br><em>RRF</em> <br><br>Regularized Random Forests</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RRF/">RRF</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.rrlda</strong> <br><em>rrlda</em> <br><br>Robust Regularized Linear Discriminant Analysis</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/rrlda/">rrlda</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.saeDNN</strong> <br><em>sae.dnn</em> <br><br>Deep neural network with weights initialized by Stacked AutoEncoder</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/deepnet/">deepnet</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">
<code>output</code> set to <code>"softmax"</code> by default.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.sda</strong> <br><em>sda</em> <br><br>Shrinkage Discriminant Analysis</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/sda/">sda</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.sparseLDA</strong> <br><em>sparseLDA</em> <br><br>Sparse Discriminant Analysis</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/sparseLDA/">sparseLDA</a><br><a href="http://www.rdocumentation.org/packages/MASS/">MASS</a><br><a href="http://www.rdocumentation.org/packages/elasticnet/">elasticnet</a>
</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass</td>
<td align="left">Arguments <code>Q</code> and <code>stop</code> are not yet provided as they depend on the task.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>classif.svm</strong> <br><em>svm</em> <br><br>Support Vector Machines (libsvm)</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/e1071/">e1071</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob<br>twoclass<br>multiclass<br>class.weights</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>classif.xgboost</strong> <br><em>xgboost</em> <br><br>eXtreme Gradient Boosting</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/xgboost/">xgboost</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob<br>twoclass<br>multiclass<br>featimp</td>
<td align="left">All settings are passed directly, rather than through <code>xgboost</code>â€™s <code>params</code> argument. <code>nrounds</code> has been set to <code>1</code> and <code>verbose</code> to <code>0</code> by default. <code>num_class</code> is set internally, so do not set this manually.</td>
</tr>
</tbody>
</table>
</div>
<div id="regression-59" class="section level1">
<h1 class="hasAnchor">
<a href="#regression-59" class="anchor"></a>Regression (59)</h1>
<p>Additional learner properties:</p>
<ul>
<li>
<em>se</em>: Standard errors can be predicted.</li>
</ul>
<table class="table">
<colgroup>
<col width="16%">
<col width="14%">
<col width="0%">
<col width="0%">
<col width="0%">
<col width="0%">
<col width="1%">
<col width="3%">
<col width="62%">
</colgroup>
<thead><tr class="header">
<th align="left">Class / Short Name / Name</th>
<th align="left">Packages</th>
<th align="center">Num.</th>
<th align="center">Fac.</th>
<th align="center">Ord.</th>
<th align="center">NAs</th>
<th align="center">Weights</th>
<th align="left">Props</th>
<th align="left">Note</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">
<strong>regr.bartMachine</strong> <br><em>bartmachine</em> <br><br>Bayesian Additive Regression Trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/bartMachine/">bartMachine</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left"></td>
<td align="left">
<code>use_missing_data</code> has been set to <code>TRUE</code> by default to allow missing data support.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.bcart</strong> <br><em>bcart</em> <br><br>Bayesian CART</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/tgp/">tgp</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.bgp</strong> <br><em>bgp</em> <br><br>Bayesian Gaussian Process</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/tgp/">tgp</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.bgpllm</strong> <br><em>bgpllm</em> <br><br>Bayesian Gaussian Process with jumps to the Limiting Linear Model</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/tgp/">tgp</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.blm</strong> <br><em>blm</em> <br><br>Bayesian Linear Model</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/tgp/">tgp</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.brnn</strong> <br><em>brnn</em> <br><br>Bayesian regularization for feed-forward neural networks</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/brnn/">brnn</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.bst</strong> <br><em>bst</em> <br><br>Gradient Boosting</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/bst/">bst</a><br><a href="http://www.rdocumentation.org/packages/rpart/">rpart</a>
</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">Renamed parameter <code>learner</code> to <code>Learner</code> due to nameclash with <code>setHyperPars</code>. Default changes: <code>Learner = "ls"</code>, <code>xval = 0</code>, and <code>maxdepth = 1</code>.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.btgp</strong> <br><em>btgp</em> <br><br>Bayesian Treed Gaussian Process</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/tgp/">tgp</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.btgpllm</strong> <br><em>btgpllm</em> <br><br>Bayesian Treed Gaussian Process with jumps to the Limiting Linear Model</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/tgp/">tgp</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.btlm</strong> <br><em>btlm</em> <br><br>Bayesian Treed Linear Model</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/tgp/">tgp</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.cforest</strong> <br><em>cforest</em> <br><br>Random Forest Based on Conditional Inference Trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/party/">party</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">featimp</td>
<td align="left">See <code>?ctree_control</code> for possible breakage for nominal features with missingness.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.crs</strong> <br><em>crs</em> <br><br>Regression Splines</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/crs/">crs</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">se</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.ctree</strong> <br><em>ctree</em> <br><br>Conditional Inference Trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/party/">party</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">See <code>?ctree_control</code> for possible breakage for nominal features with missingness.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.cubist</strong> <br><em>cubist</em> <br><br>Cubist</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/Cubist/">Cubist</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.cvglmnet</strong> <br><em>cvglmnet</em> <br><br>GLM with Lasso or Elasticnet Regularization (Cross Validated Lambda)</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/glmnet/">glmnet</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">Factors automatically get converted to dummy columns, ordered factors to integer. glmnet uses a global control object for its parameters. mlr resets all control parameters to their defaults before setting the specified parameters and after training. If you are setting glmnet.control parameters through glmnet.control, you need to save and re-set them after running the glmnet learner.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.earth</strong> <br><em>earth</em> <br><br>Multivariate Adaptive Regression Splines</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/earth/">earth</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.evtree</strong> <br><em>evtree</em> <br><br>Evolutionary learning of globally optimal trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/evtree/">evtree</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">
<code>pmutatemajor</code>, <code>pmutateminor</code>, <code>pcrossover</code>, <code>psplit</code>, and <code>pprune</code>, are scaled internally to sum to 100.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.extraTrees</strong> <br><em>extraTrees</em> <br><br>Extremely Randomized Trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/extraTrees/">extraTrees</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.FDboost</strong> <br><em>FDboost</em> <br><br>Functional linear array regression boosting</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/FDboost/">FDboost</a><br><a href="http://www.rdocumentation.org/packages/mboost/">mboost</a>
</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">functionals</td>
<td align="left">Only allow one base learner for functional covariate and one base learner for scalar covariate, the parameters for these base learners are the same. Also we currently do not support interaction between scalar covariates</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.featureless</strong> <br><em>featureless</em> <br><br>Featureless regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/mlr/">mlr</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="left">functionals</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.fnn</strong> <br><em>fnn</em> <br><br>Fast k-Nearest Neighbor</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/FNN/">FNN</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.frbs</strong> <br><em>frbs</em> <br><br>Fuzzy Rule-based Systems</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/frbs/">frbs</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.gamboost</strong> <br><em>gamboost</em> <br><br>Gradient Boosting with Smooth Components</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/mboost/">mboost</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.gausspr</strong> <br><em>gausspr</em> <br><br>Gaussian Processes</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/kernlab/">kernlab</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left">Kernel parameters have to be passed directly and not by using the <code>kpar</code> list in <code>gausspr</code>. Note that <code>fit</code> has been set to <code>FALSE</code> by default for speed.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.gbm</strong> <br><em>gbm</em> <br><br>Gradient Boosting Machine</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/gbm/">gbm</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">featimp</td>
<td align="left">
<code>keep.data</code> is set to FALSE to reduce memory requirements, <code>distribution</code> has been set to <code>"gaussian"</code> by default.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.glm</strong> <br><em>glm</em> <br><br>Generalized Linear Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/stats/">stats</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">se</td>
<td align="left">â€˜familyâ€™ must be a character and every family has its own link, i.e.Â family = â€˜gaussianâ€™, link.gaussian = â€˜identityâ€™, which is also the default. We set â€˜modelâ€™ to FALSE by default to save memory.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.glmboost</strong> <br><em>glmboost</em> <br><br>Boosting for GLMs</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/mboost/">mboost</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.glmnet</strong> <br><em>glmnet</em> <br><br>GLM with Lasso or Elasticnet Regularization</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/glmnet/">glmnet</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">Factors automatically get converted to dummy columns, ordered factors to integer. Parameter <code>s</code> (value of the regularization parameter used for predictions) is set to <code>0.1</code> by default, but needs to be tuned by the user. glmnet uses a global control object for its parameters. mlr resets all control parameters to their defaults before setting the specified parameters and after training. If you are setting glmnet.control parameters through glmnet.control, you need to save and re-set them after running the glmnet learner.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.GPfit</strong> <br><em>GPfit</em> <br><br>Gaussian Process</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/GPfit/">GPfit</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left">(1) As the optimization routine assumes that the inputs are scaled to the unit hypercube [0,1]^d, the input gets scaled for each variable by default. If this is not wanted, scale = FALSE has to be set. (2) We replace the GPfit parameter â€˜corr = list(type = â€™exponentialâ€™,power = 1.95)â€˜to be seperate parameters â€™typeâ€™ and â€˜powerâ€™, in the case of corr = list(type = â€˜maternâ€™, nu = 0.5), the seperate parameters are â€˜typeâ€™ and â€˜matern_nu_k = 0â€™, and nu is computed by â€˜nu = (2 * matern_nu_k + 1) / 2 = 0.5â€™</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.h2o.deeplearning</strong> <br><em>h2o.dl</em> <br><br>h2o.deeplearning</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/h2o/">h2o</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">The default value of <code>missing_values_handling</code> is <code>"MeanImputation"</code>, so missing values are automatically mean-imputed.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.h2o.gbm</strong> <br><em>h2o.gbm</em> <br><br>h2o.gbm</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/h2o/">h2o</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.h2o.glm</strong> <br><em>h2o.glm</em> <br><br>h2o.glm</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/h2o/">h2o</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">
<code>family</code> is always set to <code>"gaussian"</code>. The default value of <code>missing_values_handling</code> is <code>"MeanImputation"</code>, so missing values are automatically mean-imputed.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.h2o.randomForest</strong> <br><em>h2o.rf</em> <br><br>h2o.randomForest</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/h2o/">h2o</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.IBk</strong> <br><em>ibk</em> <br><br>K-Nearest Neighbours</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.kknn</strong> <br><em>kknn</em> <br><br>K-Nearest-Neighbor regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/kknn/">kknn</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.km</strong> <br><em>km</em> <br><br>Kriging</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/DiceKriging/">DiceKriging</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left">In predict, we currently always use <code>type = "SK"</code>. The extra parameter <code>jitter</code> (default is <code>FALSE</code>) enables adding a very small jitter (order 1e-12) to the x-values before prediction, as <code>predict.km</code> reproduces the exact y-values of the training data points, when you pass them in, even if the nugget effect is turned on. We further introduced <code>nugget.stability</code> which sets the <code>nugget</code> to <code>nugget.stability * var(y)</code> before each training to improve numerical stability. We recommend a setting of 10^-8</td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.ksvm</strong> <br><em>ksvm</em> <br><br>Support Vector Machines</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/kernlab/">kernlab</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">Kernel parameters have to be passed directly and not by using the <code>kpar</code> list in <code>ksvm</code>. Note that <code>fit</code> has been set to <code>FALSE</code> by default for speed.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.laGP</strong> <br><em>laGP</em> <br><br>Local Approximate Gaussian Process</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/laGP/">laGP</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">se</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.LiblineaRL2L1SVR</strong> <br><em>liblinl2l1svr</em> <br><br>L2-Regularized L1-Loss Support Vector Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/LiblineaR/">LiblineaR</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">Parameter <code>svr_eps</code> has been set to <code>0.1</code> by default.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.LiblineaRL2L2SVR</strong> <br><em>liblinl2l2svr</em> <br><br>L2-Regularized L2-Loss Support Vector Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/LiblineaR/">LiblineaR</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">
<code>type = 11</code> (the default) is primal and <code>type = 12</code> is dual problem. Parameter <code>svr_eps</code> has been set to <code>0.1</code> by default.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.lm</strong> <br><em>lm</em> <br><br>Simple Linear Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/stats/">stats</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">se</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.mars</strong> <br><em>mars</em> <br><br>Multivariate Adaptive Regression Splines</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/mda/">mda</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.mob</strong> <br><em>mob</em> <br><br>Model-based Recursive Partitioning Yielding a Tree with Fitted Models Associated with each Terminal Node</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/party/">party</a><br><a href="http://www.rdocumentation.org/packages/modeltools/">modeltools</a>
</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.nnet</strong> <br><em>nnet</em> <br><br>Neural Network</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/nnet/">nnet</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">
<code>size</code> has been set to <code>3</code> by default.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.nodeHarvest</strong> <br><em>nodeHarvest</em> <br><br>Node Harvest</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/nodeHarvest/">nodeHarvest</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.pcr</strong> <br><em>pcr</em> <br><br>Principal Component Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/pls/">pls</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.penalized</strong> <br><em>penalized</em> <br><br>Penalized Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/penalized/">penalized</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">trace=FALSE was set by default to disable logging output.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.plsr</strong> <br><em>plsr</em> <br><br>Partial Least Squares Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/pls/">pls</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.randomForest</strong> <br><em>rf</em> <br><br>Random Forest</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/randomForest/">randomForest</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="left">featimp<br>oobpreds<br>se</td>
<td align="left">See <code><a href="../../reference/regr.randomForest.html">?regr.randomForest</a></code> for information about se estimation. Note that the rf can freeze the R process if trained on a task with 1 feature which is constant. This can happen in feature forward selection, also due to resampling, and you need to remove such features with removeConstantFeatures. keep.inbag is NULL by default but if predict.type = â€˜seâ€™ and se.method = â€˜jackknifeâ€™ (the default) then it is automatically set to TRUE.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.randomForestSRC</strong> <br><em>rfsrc</em> <br><br>Random Forest</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/randomForestSRC/">randomForestSRC</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">featimp<br>oobpreds</td>
<td align="left">
<code>na.action</code> has been set to <code>"na.impute"</code> by default to allow missing data support.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.ranger</strong> <br><em>ranger</em> <br><br>Random Forests</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/ranger/">ranger</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">featimp<br>oobpreds<br>se</td>
<td align="left">By default, internal parallelization is switched off (<code>num.threads = 1</code>), <code>verbose</code> output is disabled, <code>respect.unordered.factors</code> is set to <code>order</code> for all splitrules.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.rknn</strong> <br><em>rknn</em> <br><br>Random k-Nearest-Neighbors</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/rknn/">rknn</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.rpart</strong> <br><em>rpart</em> <br><br>Decision Tree</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/rpart/">rpart</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">featimp</td>
<td align="left">
<code>xval</code> has been set to <code>0</code> by default for speed.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.RRF</strong> <br><em>RRF</em> <br><br>Regularized Random Forests</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RRF/">RRF</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="left">featimp</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.rsm</strong> <br><em>rsm</em> <br><br>Response Surface Regression</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/rsm/">rsm</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">You select the order of the regression by using <code>modelfun = "FO"</code> (first order), <code>"TWI"</code> (two-way interactions, this is with 1st oder terms!) and <code>"SO"</code> (full second order).</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.rvm</strong> <br><em>rvm</em> <br><br>Relevance Vector Machine</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/kernlab/">kernlab</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">Kernel parameters have to be passed directly and not by using the <code>kpar</code> list in <code>rvm</code>. Note that <code>fit</code> has been set to <code>FALSE</code> by default for speed.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.slim</strong> <br><em>slim</em> <br><br>Sparse Linear Regression using Nonsmooth Loss Functions and L1 Regularization</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/flare/">flare</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">
<code>lambda.idx</code> has been set to <code>3</code> by default.</td>
</tr>
<tr class="even">
<td align="left">
<strong>regr.svm</strong> <br><em>svm</em> <br><br>Support Vector Machines (libsvm)</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/e1071/">e1071</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>regr.xgboost</strong> <br><em>xgboost</em> <br><br>eXtreme Gradient Boosting</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/xgboost/">xgboost</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">featimp</td>
<td align="left">All settings are passed directly, rather than through <code>xgboost</code>â€™s <code>params</code> argument. <code>nrounds</code> has been set to <code>1</code> and <code>verbose</code> to <code>0</code> by default.</td>
</tr>
</tbody>
</table>
</div>
<div id="survival-analysis-12" class="section level1">
<h1 class="hasAnchor">
<a href="#survival-analysis-12" class="anchor"></a>Survival analysis (12)</h1>
<p>Additional learner properties:</p>
<ul>
<li>
<em>prob</em>: Probabilities can be predicted,</li>
<li>
<em>rcens</em>, <em>lcens</em>, <em>icens</em>: The learner can handle right, left and/or interval censored data.</li>
</ul>
<table class="table">
<colgroup>
<col width="19%">
<col width="15%">
<col width="0%">
<col width="0%">
<col width="0%">
<col width="0%">
<col width="0%">
<col width="2%">
<col width="59%">
</colgroup>
<thead><tr class="header">
<th align="left">Class / Short Name / Name</th>
<th align="left">Packages</th>
<th align="center">Num.</th>
<th align="center">Fac.</th>
<th align="center">Ord.</th>
<th align="center">NAs</th>
<th align="center">Weights</th>
<th align="left">Props</th>
<th align="left">Note</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">
<strong>surv.cforest</strong> <br><em>crf</em> <br><br>Random Forest based on Conditional Inference Trees</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/party/">party</a><br><a href="http://www.rdocumentation.org/packages/survival/">survival</a>
</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">featimp</td>
<td align="left">See <code>?ctree_control</code> for possible breakage for nominal features with missingness.</td>
</tr>
<tr class="even">
<td align="left">
<strong>surv.CoxBoost</strong> <br><em>coxboost</em> <br><br>Cox Proportional Hazards Model with Componentwise Likelihood based Boosting</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/CoxBoost/">CoxBoost</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">Factors automatically get converted to dummy columns, ordered factors to integer.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>surv.coxph</strong> <br><em>coxph</em> <br><br>Cox Proportional Hazard Model</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/survival/">survival</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>surv.cv.CoxBoost</strong> <br><em>cv.CoxBoost</em> <br><br>Cox Proportional Hazards Model with Componentwise Likelihood based Boosting, tuned for the optimal number of boosting steps</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/CoxBoost/">CoxBoost</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">Factors automatically get converted to dummy columns, ordered factors to integer.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>surv.cvglmnet</strong> <br><em>cvglmnet</em> <br><br>GLM with Regularization (Cross Validated Lambda)</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/glmnet/">glmnet</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">Factors automatically get converted to dummy columns, ordered factors to integer.</td>
</tr>
<tr class="even">
<td align="left">
<strong>surv.gamboost</strong> <br><em>gamboost</em> <br><br>Gradient boosting with smooth components</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/survival/">survival</a><br><a href="http://www.rdocumentation.org/packages/mboost/">mboost</a>
</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">
<code>family</code> has been set to <code>CoxPH()</code> by default.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>surv.gbm</strong> <br><em>gbm</em> <br><br>Gradient Boosting Machine</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/gbm/">gbm</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">featimp</td>
<td align="left">
<code>keep.data</code> is set to FALSE to reduce memory requirements.</td>
</tr>
<tr class="even">
<td align="left">
<strong>surv.glmboost</strong> <br><em>glmboost</em> <br><br>Gradient Boosting with Componentwise Linear Models</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/survival/">survival</a><br><a href="http://www.rdocumentation.org/packages/mboost/">mboost</a>
</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">
<code>family</code> has been set to <code>CoxPH()</code> by default.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>surv.glmnet</strong> <br><em>glmnet</em> <br><br>GLM with Regularization</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/glmnet/">glmnet</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left"></td>
<td align="left">Factors automatically get converted to dummy columns, ordered factors to integer. Parameter <code>s</code> (value of the regularization parameter used for predictions) is set to <code>0.1</code> by default, but needs to be tuned by the user. glmnet uses a global control object for its parameters. mlr resets all control parameters to their defaults before setting the specified parameters and after training. If you are setting glmnet.control parameters through glmnet.control, you need to save and re-set them after running the glmnet learner.</td>
</tr>
<tr class="even">
<td align="left">
<strong>surv.randomForestSRC</strong> <br><em>rfsrc</em> <br><br>Random Forest</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/survival/">survival</a><br><a href="http://www.rdocumentation.org/packages/randomForestSRC/">randomForestSRC</a>
</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">featimp<br>oobpreds</td>
<td align="left">
<code>na.action</code> has been set to <code>"na.impute"</code> by default to allow missing data support.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>surv.ranger</strong> <br><em>ranger</em> <br><br>Random Forests</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/ranger/">ranger</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="left">featimp</td>
<td align="left">By default, internal parallelization is switched off (<code>num.threads = 1</code>), <code>verbose</code> output is disabled, <code>respect.unordered.factors</code> is set to <code>order</code> for all splitrules. All settings are changeable.</td>
</tr>
<tr class="even">
<td align="left">
<strong>surv.rpart</strong> <br><em>rpart</em> <br><br>Survival Tree</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/rpart/">rpart</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">featimp</td>
<td align="left">
<code>xval</code> has been set to <code>0</code> by default for speed.</td>
</tr>
</tbody>
</table>
</div>
<div id="cluster-analysis-10" class="section level1">
<h1 class="hasAnchor">
<a href="#cluster-analysis-10" class="anchor"></a>Cluster analysis (10)</h1>
<p>Additional learner properties:</p>
<ul>
<li>
<em>prob</em>: Probabilities can be predicted.</li>
</ul>
<table class="table">
<colgroup>
<col width="19%">
<col width="22%">
<col width="1%">
<col width="1%">
<col width="1%">
<col width="0%">
<col width="1%">
<col width="1%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th align="left">Class / Short Name / Name</th>
<th align="left">Packages</th>
<th align="center">Num.</th>
<th align="center">Fac.</th>
<th align="center">Ord.</th>
<th align="center">NAs</th>
<th align="center">Weights</th>
<th align="left">Props</th>
<th align="left">Note</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">
<strong>cluster.cmeans</strong> <br><em>cmeans</em> <br><br>Fuzzy C-Means Clustering</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/e1071/">e1071</a><br><a href="http://www.rdocumentation.org/packages/clue/">clue</a>
</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob</td>
<td align="left">The <code>predict</code> method uses <code>cl_predict</code> from the <code>clue</code> package to compute the cluster memberships for new data. The default <code>centers = 2</code> is added so the method runs without setting parameters, but this must in reality of course be changed by the user.</td>
</tr>
<tr class="even">
<td align="left">
<strong>cluster.Cobweb</strong> <br><em>cobweb</em> <br><br>Cobweb Clustering Algorithm</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>cluster.dbscan</strong> <br><em>dbscan</em> <br><br>DBScan Clustering</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/fpc/">fpc</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">A cluster index of NA indicates noise points. Specify <code>method = 'dist'</code> if the data should be interpreted as dissimilarity matrix or object. Otherwise Euclidean distances will be used.</td>
</tr>
<tr class="even">
<td align="left">
<strong>cluster.EM</strong> <br><em>em</em> <br><br>Expectation-Maximization Clustering</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">
<strong>cluster.FarthestFirst</strong> <br><em>farthestfirst</em> <br><br>FarthestFirst Clustering Algorithm</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>cluster.kkmeans</strong> <br><em>kkmeans</em> <br><br>Kernel K-Means</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/kernlab/">kernlab</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">
<code>centers</code> has been set to <code>2L</code> by default. The nearest center in kernel distance determines cluster assignment of new data points. Kernel parameters have to be passed directly and not by using the <code>kpar</code> list in <code>kkmeans</code>
</td>
</tr>
<tr class="odd">
<td align="left">
<strong>cluster.kmeans</strong> <br><em>kmeans</em> <br><br>K-Means</td>
<td align="left">
<a href="http://www.rdocumentation.org/packages/stats/">stats</a><br><a href="http://www.rdocumentation.org/packages/clue/">clue</a>
</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob</td>
<td align="left">The <code>predict</code> method uses <code>cl_predict</code> from the <code>clue</code> package to compute the cluster memberships for new data. The default <code>centers = 2</code> is added so the method runs without setting parameters, but this must in reality of course be changed by the user.</td>
</tr>
<tr class="even">
<td align="left">
<strong>cluster.MiniBatchKmeans</strong> <br><em>MBatchKmeans</em> <br><br>MiniBatchKmeans</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/ClusterR/">ClusterR</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left">prob</td>
<td align="left">Calls MiniBatchKmeans of package ClusterR. Argument <code>clusters</code> has default value of 2 if not provided by user.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>cluster.SimpleKMeans</strong> <br><em>simplekmeans</em> <br><br>K-Means Clustering</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>cluster.XMeans</strong> <br><em>xmeans</em> <br><br>XMeans (k-means with automatic determination of k)</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/RWeka/">RWeka</a></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left">You may have to install the XMeans Weka package: <code>WPM('install-package', 'XMeans')</code>.</td>
</tr>
</tbody>
</table>
</div>
<div id="cost-sensitive-classification" class="section level1">
<h1 class="hasAnchor">
<a href="#cost-sensitive-classification" class="anchor"></a>Cost-sensitive classification</h1>
<p>For <em>ordinary misclassification costs</em> you can use all the standard classification methods listed above.</p>
<p>For <em>example-dependent costs</em> there are several ways to generate cost-sensitive learners from ordinary regression and classification learners. See section <a href="cost_sensitive_classif.html" target="_blank">cost-sensitive classification</a> and the documentation of <code><a href="../../reference/makeCostSensClassifWrapper.html">makeCostSensClassifWrapper()</a></code>, <code><a href="../../reference/makeCostSensRegrWrapper.html">makeCostSensRegrWrapper()</a></code> and <code><a href="../../reference/makeCostSensWeightedPairsWrapper.html">makeCostSensWeightedPairsWrapper()</a></code> for details.</p>
</div>
<div id="multilabel-classification-3" class="section level1">
<h1 class="hasAnchor">
<a href="#multilabel-classification-3" class="anchor"></a>Multilabel classification (3)</h1>
<table class="table">
<colgroup>
<col width="34%">
<col width="25%">
<col width="1%">
<col width="1%">
<col width="1%">
<col width="1%">
<col width="2%">
<col width="2%">
<col width="27%">
</colgroup>
<thead><tr class="header">
<th align="left">Class / Short Name / Name</th>
<th align="left">Packages</th>
<th align="center">Num.</th>
<th align="center">Fac.</th>
<th align="center">Ord.</th>
<th align="center">NAs</th>
<th align="center">Weights</th>
<th align="left">Props</th>
<th align="left">Note</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">
<strong>multilabel.cforest</strong> <br><em>cforest</em> <br><br>Random forest based on conditional inference trees</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/party/">party</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">
<strong>multilabel.randomForestSRC</strong> <br><em>rfsrc</em> <br><br>Random Forest</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/randomForestSRC/">randomForestSRC</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="left">prob</td>
<td align="left">
<code>na.action</code> has been set to <code>na.impute</code> by default to allow missing data support.</td>
</tr>
<tr class="odd">
<td align="left">
<strong>multilabel.rFerns</strong> <br><em>rFerns</em> <br><br>Random ferns</td>
<td align="left"><a href="http://www.rdocumentation.org/packages/rFerns/">rFerns</a></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>Moreover, you can use the binary relevance method to apply ordinary classification learners to the multilabel problem. See the documentation of function <code><a href="../../reference/makeMultilabelBinaryRelevanceWrapper.html">makeMultilabelBinaryRelevanceWrapper()</a></code> and the tutorial section on <a href="multilabel.html" target="_blank">multilabel classification</a> for details.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#classification-82">Classification (82)</a></li>
      <li><a href="#regression-59">Regression (59)</a></li>
      <li><a href="#survival-analysis-12">Survival analysis (12)</a></li>
      <li><a href="#cluster-analysis-10">Cluster analysis (10)</a></li>
      <li><a href="#cost-sensitive-classification">Cost-sensitive classification</a></li>
      <li><a href="#multilabel-classification-3">Multilabel classification (3)</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><!--<div class="copyright">
  <p>Developed by Bernd Bischl, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Zachary Jones, Giuseppe Casalicchio, Mason Gallo, Patrick Schratz.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>
--></footer>
</div>

   
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script><script type="text/javascript"> docsearch({
â€ƒapiKey: 'e300ecafdf04fe1199e3339c825ce7d0',
â€ƒindexName: 'mlr',
â€ƒinputSelector: 'input#search-input.form-control',
â€ƒdebug: false // Set debug to true if you want to inspect the dropdown
});
</script>
</body>
</html>
